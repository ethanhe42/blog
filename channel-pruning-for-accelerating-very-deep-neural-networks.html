<!DOCTYPE html><html lang="en"><head><link rel="shortcut icon" href="/favicon.png"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/manifest.json"/><meta charSet="utf-8"/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta property="og:description" content="Yihui He, AI research scientist / full stack engineer"/><meta name="theme-color" content="#EB625A"/><meta property="og:type" content="website"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4253216309174736" crossorigin="anonymous"></script><meta property="og:title" content="Channel Pruning for Accelerating Very Deep Neural Networks"/><meta property="og:site_name" content="Yihui He"/><meta name="twitter:title" content="Channel Pruning for Accelerating Very Deep Neural Networks"/><meta property="twitter:domain" content="yihui-he.github.io"/><meta name="twitter:creator" content="@he_yi_hui"/><meta name="description" content="Yihui He, AI research scientist / full stack engineer"/><meta property="og:description" content="Yihui He, AI research scientist / full stack engineer"/><meta name="twitter:description" content="Yihui He, AI research scientist / full stack engineer"/><meta name="twitter:card" content="summary"/><link rel="canonical" href="https://yihui-he.github.io/channel-pruning-for-accelerating-very-deep-neural-networks"/><meta property="og:url" content="https://yihui-he.github.io/channel-pruning-for-accelerating-very-deep-neural-networks"/><meta property="twitter:url" content="https://yihui-he.github.io/channel-pruning-for-accelerating-very-deep-neural-networks"/><title>Channel Pruning for Accelerating Very Deep Neural Networks</title><meta name="next-head-count" content="20"/><link rel="preload" href="/blog/_next/static/css/65d691ce4d9328bfefea.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/65d691ce4d9328bfefea.css" data-n-g=""/><link rel="preload" href="/blog/_next/static/css/4b67152b49ef8d389eef.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/4b67152b49ef8d389eef.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/blog/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/blog/_next/static/chunks/webpack-ac2aaa5a7a1baa4824dd.js" defer=""></script><script src="/blog/_next/static/chunks/framework-c93ed74a065331c4bd75.js" defer=""></script><script src="/blog/_next/static/chunks/main-0989120ac94443065aa9.js" defer=""></script><script src="/blog/_next/static/chunks/pages/_app-93d47364a9b4c8c53030.js" defer=""></script><script src="/blog/_next/static/chunks/1bfc9850-762e4e08544c8bec659c.js" defer=""></script><script src="/blog/_next/static/chunks/ae51ba48-7f31b5cf321fe3268476.js" defer=""></script><script src="/blog/_next/static/chunks/d7eeaac4-07e2c37279f27c6f41bc.js" defer=""></script><script src="/blog/_next/static/chunks/875-291d2103666b9d9c5329.js" defer=""></script><script src="/blog/_next/static/chunks/270-37c3d38a9cca8a1322a7.js" defer=""></script><script src="/blog/_next/static/chunks/pages/%5BpageId%5D-c63ce9df319d103b914e.js" defer=""></script><script src="/blog/_next/static/wS-AqNTKr-7sWPE_cAUmu/_buildManifest.js" defer=""></script><script src="/blog/_next/static/wS-AqNTKr-7sWPE_cAUmu/_ssgManifest.js" defer=""></script></head><body><script src="noflash.js"></script><div id="__next"><div class="notion notion-app light-mode notion-block-fad54c70af5c42a3a00aff18bea9c382"><div class="notion-viewport"></div><div class="notion-frame"><header class="notion-header"><div class="nav-header"><div class="breadcrumbs"><a class="breadcrumb" href="/blog"><img class="icon notion-page-icon" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F63e89fe9-f5cd-4414-be0e-53d91aa54fc3%2Fme_small.jpg?table=block&amp;id=bd32b787-e471-49f3-8941-174a9c6846b6&amp;cache=v2" alt="Yihui He’s Blog" loading="lazy"/><span class="title">Yihui He’s Blog</span></a><span class="spacer">/</span><div class="breadcrumb active"><span class="title">Channel Pruning for Accelerating Very Deep Neural Networks</span></div></div><div class="rhs"></div></div></header><div class="notion-page-scroller"><main class="notion-page notion-page-no-cover notion-page-no-icon notion-page-has-text-icon notion-full-page"><h1 class="notion-title">Channel Pruning for Accelerating Very Deep Neural Networks</h1><div class="notion-page-content notion-page-content-has-aside notion-page-content-has-toc"><article class="notion-page-content-inner"><div class="notion-row"><a target="_blank" rel="noopener noreferrer" class="notion-bookmark notion-block-0fe67c125bb44aec98340ba7c001935d" href="https://github.com/yihui-he/channel-pruning"><div><div class="notion-bookmark-title">GitHub - yihui-he/channel-pruning: Channel Pruning for Accelerating Very Deep Neural Networks (ICCV&#x27;17)</div><div class="notion-bookmark-description">You can&#x27;t perform that action at this time. You signed in with another tab or window. You signed out in another tab or window. Reload to refresh your session. Reload to refresh your session.</div><div class="notion-bookmark-link"><img src="https://github.com/favicon.ico" alt="GitHub - yihui-he/channel-pruning: Channel Pruning for Accelerating Very Deep Neural Networks (ICCV&#x27;17)" loading="lazy"/><div>https://github.com/yihui-he/channel-pruning</div></div></div><div class="notion-bookmark-image"><img src="https://repository-images.githubusercontent.com/100935205/1d782480-e3a6-11e9-935b-3e5a7f46040e" alt="GitHub - yihui-he/channel-pruning: Channel Pruning for Accelerating Very Deep Neural Networks (ICCV&#x27;17)" loading="lazy"/></div></a></div><div class="notion-row"><a target="_blank" rel="noopener noreferrer" class="notion-bookmark notion-block-e7a3773620d44b45bc004f01266c96a9" href="https://arxiv.org/abs/1707.06168"><div><div class="notion-bookmark-title">Channel Pruning for Accelerating Very Deep Neural Networks</div><div class="notion-bookmark-description">In this paper, we introduce a new channel pruning method to accelerate very deep convolutional neural networks.Given a trained CNN model, we propose an iterative two-step algorithm to effectively prune each layer, by a LASSO regression based channel selection and least square reconstruction. We further generalize this algorithm to multi-layer and multi-branch cases.</div><div class="notion-bookmark-link"><img src="https://static.arxiv.org/static/browse/0.3.3/images/icons/favicon.ico" alt="Channel Pruning for Accelerating Very Deep Neural Networks" loading="lazy"/><div>https://arxiv.org/abs/1707.06168</div></div></div><div class="notion-bookmark-image"><img src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png" alt="Channel Pruning for Accelerating Very Deep Neural Networks" loading="lazy"/></div></a></div><div class="notion-text notion-block-1ad84510e4d742cdb8fdcb6a7604cb37"><b>ICCV 2017</b>, by <a target="_blank" rel="noopener noreferrer" class="notion-link" href="http://yihui-he.github.io/">Yihui He</a>, <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&amp;hl=en&amp;oi=ao">Xiangyu Zhang</a> and <a target="_blank" rel="noopener noreferrer" class="notion-link" href="http://jiansun.org/">Jian Sun</a></div><div class="notion-text notion-block-1e99a0fad68743c69271943f352d8302">Please have a look our new works on compressing deep models: </div><ul class="notion-list notion-list-disc notion-block-982b8e1adaac451b935b3022840a10e4"><li><a target="_blank" rel="noopener noreferrer" class="notion-link" href="http://openaccess.thecvf.com/content_ECCV_2018/html/Yihui_He_AMC_Automated_Model_ECCV_2018_paper.html">AMC: AutoML for Model Compression and Acceleration on Mobile Devices</a> <b>ECCV’18</b>, which combines channel pruning and reinforcement learning to further accelerate CNN. <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/mit-han-lab/amc-release">code</a> and <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/mit-han-lab/amc-compressed-models">models</a> are available! </li></ul><ul class="notion-list notion-list-disc notion-block-791437f21abe4f36a3a5547101a76e74"><li><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://arxiv.org/abs/1809.08458">AddressNet: Shift-Based Primitives for Efficient Convolutional Neural Networks</a> <b>WACV’19</b>. We propose a family of efficient networks based on Shift operation. </li></ul><ul class="notion-list notion-list-disc notion-block-c0407ab47e2d430996405f55c0d5e147"><li><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://arxiv.org/abs/1907.12629">MoBiNet: A Mobile Binary Network for Image Classification</a> <b>WACV’20</b> Binarized MobileNets.</li></ul><div class="notion-text notion-block-1a68fe58b03f42508ad743ed3441ed9d">In this repository, we released code for the following models:</div><div class="notion-collection notion-block-b90ce08ae846474c9299624837df1adf"><div class="notion-collection-header" style="padding-left:96px;padding-right:96px"></div><div class="notion-table" style="width:1024px;max-width:1024px"><div class="notion-table-view" style="padding-left:96px;padding-right:96px"><div class="notion-table-header"><div class="notion-table-header-inner"><div class="notion-table-th"><div class="notion-table-view-header-cell" style="width:200px"><div class="notion-table-view-header-cell-inner"><div class="notion-collection-column-title"><svg viewBox="0 0 14 14" class="notion-collection-column-title-icon"><path d="M7 4.568a.5.5 0 00-.5-.5h-6a.5.5 0 00-.5.5v1.046a.5.5 0 00.5.5h6a.5.5 0 00.5-.5V4.568zM.5 1a.5.5 0 00-.5.5v1.045a.5.5 0 00.5.5h12a.5.5 0 00.5-.5V1.5a.5.5 0 00-.5-.5H.5zM0 8.682a.5.5 0 00.5.5h11a.5.5 0 00.5-.5V7.636a.5.5 0 00-.5-.5H.5a.5.5 0 00-.5.5v1.046zm0 3.068a.5.5 0 00.5.5h9a.5.5 0 00.5-.5v-1.045a.5.5 0 00-.5-.5h-9a.5.5 0 00-.5.5v1.045z"></path></svg><div class="notion-collection-column-title-body">model</div></div></div></div></div><div class="notion-table-th"><div class="notion-table-view-header-cell" style="width:280px"><div class="notion-table-view-header-cell-inner"><div class="notion-collection-column-title"><svg viewBox="0 0 14 14" class="notion-collection-column-title-icon"><path d="M7.74 8.697a.81.81 0 01.073.308.894.894 0 01-.9.888.867.867 0 01-.825-.592l-.333-.961H2.058l-.333.961a.882.882 0 01-.838.592A.884.884 0 010 9.005c0-.11.025-.222.062-.308l2.403-6.211c.222-.58.776-.986 1.442-.986.653 0 1.22.407 1.442.986l2.39 6.211zM2.6 6.824h2.613L3.907 3.102 2.6 6.824zm8.8-3.118c1.355 0 2.6.542 2.6 2.255V9.08a.8.8 0 01-.789.814.797.797 0 01-.788-.703c-.395.468-1.097.764-1.874.764-.949 0-2.07-.64-2.07-1.972 0-1.392 1.121-1.897 2.07-1.897.789 0 1.491.246 1.886.727v-.826c0-.604-.518-.998-1.306-.998-.469 0-.888.123-1.32.394a.64.64 0 01-.307.086.602.602 0 01-.592-.604c0-.221.123-.419.284-.517a3.963 3.963 0 012.206-.641zm-.222 5.188c.505 0 .998-.172 1.257-.517v-.74c-.259-.345-.752-.517-1.257-.517-.616 0-1.122.332-1.122.9 0 .554.506.874 1.122.874zM.656 11.125h12.688a.656.656 0 110 1.313H.656a.656.656 0 110-1.313z"></path></svg><div class="notion-collection-column-title-body">Speed-up</div></div></div></div></div><div class="notion-table-th"><div class="notion-table-view-header-cell" style="width:200px"><div class="notion-table-view-header-cell-inner"><div class="notion-collection-column-title"><svg viewBox="0 0 14 14" class="notion-collection-column-title-icon"><path d="M7 4.568a.5.5 0 00-.5-.5h-6a.5.5 0 00-.5.5v1.046a.5.5 0 00.5.5h6a.5.5 0 00.5-.5V4.568zM.5 1a.5.5 0 00-.5.5v1.045a.5.5 0 00.5.5h12a.5.5 0 00.5-.5V1.5a.5.5 0 00-.5-.5H.5zM0 8.682a.5.5 0 00.5.5h11a.5.5 0 00.5-.5V7.636a.5.5 0 00-.5-.5H.5a.5.5 0 00-.5.5v1.046zm0 3.068a.5.5 0 00.5.5h9a.5.5 0 00.5-.5v-1.045a.5.5 0 00-.5-.5h-9a.5.5 0 00-.5.5v1.045z"></path></svg><div class="notion-collection-column-title-body">Accuracy</div></div></div></div></div></div></div><div class="notion-table-header-placeholder"></div><div class="notion-table-body"><div class="notion-table-row"><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/channel_pruning_5x">VGG-16 channel pruning</a></span></div><div class="notion-table-cell notion-table-cell-title" style="width:280px"><span class="notion-property notion-property-title"><a class="notion-page-link" href="/blog/5x"><span class="notion-page-title"><svg class="notion-page-title-icon notion-page-icon" alt="5x" viewBox="0 0 30 30" width="16"><path d="M16,1H4v28h22V11L16,1z M16,3.828L23.172,11H16V3.828z M24,27H6V3h8v10h10V27z M8,17h14v-2H8V17z M8,21h14v-2H8V21z M8,25h14v-2H8V25z"></path></svg><span class="notion-page-title-text">5x</span></span></a></span></div><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text">88.1 (Top-5), 67.8 (Top-1)</span></div></div><div class="notion-table-row"><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/VGG-16_3C4x">VGG-16 3C</a></span></div><div class="notion-table-cell notion-table-cell-title" style="width:280px"><span class="notion-property notion-property-title"><a class="notion-page-link" href="/blog/4x"><span class="notion-page-title"><svg class="notion-page-title-icon notion-page-icon" alt="4x" viewBox="0 0 30 30" width="16"><path d="M16,1H4v28h22V11L16,1z M16,3.828L23.172,11H16V3.828z M24,27H6V3h8v10h10V27z M8,17h14v-2H8V17z M8,21h14v-2H8V21z M8,25h14v-2H8V25z"></path></svg><span class="notion-page-title-text">4x</span></span></a></span></div><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text">89.9 (Top-5), 70.6 (Top-1)</span></div></div><div class="notion-table-row"><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/ResNet-50-2X">ResNet-50</a></span></div><div class="notion-table-cell notion-table-cell-title" style="width:280px"><span class="notion-property notion-property-title"><a class="notion-page-link" href="/blog/2x"><span class="notion-page-title"><svg class="notion-page-title-icon notion-page-icon" alt="2x" viewBox="0 0 30 30" width="16"><path d="M16,1H4v28h22V11L16,1z M16,3.828L23.172,11H16V3.828z M24,27H6V3h8v10h10V27z M8,17h14v-2H8V17z M8,21h14v-2H8V21z M8,25h14v-2H8V25z"></path></svg><span class="notion-page-title-text">2x</span></span></a></span></div><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text">90.8 (Top-5), 72.3 (Top-1)</span></div></div><div class="notion-table-row"><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X">faster RCNN</a></span></div><div class="notion-table-cell notion-table-cell-title" style="width:280px"><span class="notion-property notion-property-title"><a class="notion-page-link" href="/blog/2x"><span class="notion-page-title"><svg class="notion-page-title-icon notion-page-icon" alt="2x" viewBox="0 0 30 30" width="16"><path d="M16,1H4v28h22V11L16,1z M16,3.828L23.172,11H16V3.828z M24,27H6V3h8v10h10V27z M8,17h14v-2H8V17z M8,21h14v-2H8V21z M8,25h14v-2H8V25z"></path></svg><span class="notion-page-title-text">2x</span></span></a></span></div><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text">36.7 (AP@.50:.05:.95)</span></div></div><div class="notion-table-row"><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X">faster RCNN</a></span></div><div class="notion-table-cell notion-table-cell-title" style="width:280px"><span class="notion-property notion-property-title"><a class="notion-page-link" href="/blog/4x"><span class="notion-page-title"><svg class="notion-page-title-icon notion-page-icon" alt="4x" viewBox="0 0 30 30" width="16"><path d="M16,1H4v28h22V11L16,1z M16,3.828L23.172,11H16V3.828z M24,27H6V3h8v10h10V27z M8,17h14v-2H8V17z M8,21h14v-2H8V21z M8,25h14v-2H8V25z"></path></svg><span class="notion-page-title-text">4x</span></span></a></span></div><div class="notion-table-cell notion-table-cell-text" style="width:200px"><span class="notion-property notion-property-text">35.1 (AP@.50:.05:.95)</span></div></div></div></div></div></div><div class="notion-text notion-block-e25c4d40d27947c9ab928e461291a95e">3C method combined spatial decomposition (<a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://arxiv.org/abs/1405.3866">Speeding up Convolutional Neural Networks with Low Rank Expansions</a>) and channel decomposition (<a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://arxiv.org/abs/1505.06798">Accelerating Very Deep Convolutional Networks for Classification and Detection</a>) (mentioned in 4.1.2)</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-be3df79ddf624f7ca854369a0113d0aa" data-id="be3df79ddf624f7ca854369a0113d0aa"><span><div id="be3df79ddf624f7ca854369a0113d0aa" class="notion-header-anchor"></div><a class="notion-hash-link" href="#be3df79ddf624f7ca854369a0113d0aa" title="Citation"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Citation</span></span></h4><div class="notion-text notion-block-f42bf102ce2f400f9f57e3c7f4be2be9">If you find the code useful in your research, please consider citing:</div><pre class="notion-code"><code class="language-plain text">@InProceedings<span class="token punctuation">{</span>He_2017_ICCV<span class="token punctuation">,</span>
author <span class="token operator">=</span> <span class="token punctuation">{</span>He<span class="token punctuation">,</span> Yihui and Zhang<span class="token punctuation">,</span> Xiangyu and Sun<span class="token punctuation">,</span> Jian<span class="token punctuation">}</span><span class="token punctuation">,</span>
title <span class="token operator">=</span> <span class="token punctuation">{</span>Channel Pruning <span class="token keyword">for</span> Accelerating Very Deep Neural Networks<span class="token punctuation">}</span><span class="token punctuation">,</span>
booktitle <span class="token operator">=</span> <span class="token punctuation">{</span>The <span class="token constant">IEEE</span> International Conference on Computer <span class="token function">Vision</span> <span class="token punctuation">(</span><span class="token constant">ICCV</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
month <span class="token operator">=</span> <span class="token punctuation">{</span>Oct<span class="token punctuation">}</span><span class="token punctuation">,</span>
year <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">2017</span><span class="token punctuation">}</span>
<span class="token punctuation">}</span></code></pre><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-51730754003241d1bcc010a877c82a3d" data-id="51730754003241d1bcc010a877c82a3d"><span><div id="51730754003241d1bcc010a877c82a3d" class="notion-header-anchor"></div><a class="notion-hash-link" href="#51730754003241d1bcc010a877c82a3d" title="requirements"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">requirements</span></span></h4><ol start="1" class="notion-list notion-list-numbered notion-block-76a535f3288243e3862ee39b1e3cccf8"><li>Python3 packages you might not have: <code class="notion-inline-code">scipy</code>, <code class="notion-inline-code">sklearn</code>, <code class="notion-inline-code">easydict</code>, use <code class="notion-inline-code">sudo pip3 install</code> to install.</li></ol><ol start="2" class="notion-list notion-list-numbered notion-block-049d4b641f404de6a23b0d25df0efd5e"><li>For finetuning with 128 batch size, 4 GPUs (~11G of memory)</li></ol><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-843276d929654679a55a6fdff93cf0e4" data-id="843276d929654679a55a6fdff93cf0e4"><span><div id="843276d929654679a55a6fdff93cf0e4" class="notion-header-anchor"></div><a class="notion-hash-link" href="#843276d929654679a55a6fdff93cf0e4" title="Installation (sufficient for the demo)"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Installation (sufficient for the demo)</span></span></h4><ol start="1" class="notion-list notion-list-numbered notion-block-8e238688b24845849d7b0044735e3956"><li>Clone the repository</li><ol class="notion-list notion-list-numbered notion-block-8e238688b24845849d7b0044735e3956"><pre class="notion-code"><code class="language-bash"><span class="token comment"># Make sure to clone with --recursive</span>
 <span class="token function">git</span> clone --recursive https://github.com/yihui-he/channel-pruning.git</code></pre></ol></ol><ol start="2" class="notion-list notion-list-numbered notion-block-ee16fc173c3747499ddfcbcf8f8d3dfe"><li>Build <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/caffe-pro">my Caffe</a> fork (which support bicubic interpolation and resizing image shorter side to 256 then crop to 224x224) </li><ol class="notion-list notion-list-numbered notion-block-ee16fc173c3747499ddfcbcf8f8d3dfe"><pre class="notion-code"><code class="language-bash"><span class="token builtin class-name">cd</span> caffe

 <span class="token comment"># If you're experienced with Caffe and have all of the requirements installed, then simply do:</span>
 <span class="token function">make</span> all -j8 <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> pycaffe
 <span class="token comment"># Or follow the Caffe installation instructions here:</span>
 <span class="token comment"># http://caffe.berkeleyvision.org/installation.html</span>

 <span class="token comment"># you might need to add pycaffe to PYTHONPATH, if you've already had a caffe before</span></code></pre></ol></ol><ol start="3" class="notion-list notion-list-numbered notion-block-bdbd1e87a99a4adaa1234471294cdb7f"><li>Download ImageNet classification dataset http://www.image-net.org/download-images</li></ol><ol start="4" class="notion-list notion-list-numbered notion-block-b4caea599ccc4b9fb8f8283793755973"><li>Specify imagenet <code class="notion-inline-code">source</code> path in <code class="notion-inline-code">temp/vgg.prototxt</code> (line 12 and 36)</li></ol><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-23c6b6357e094a2da0922418e82d7a76" data-id="23c6b6357e094a2da0922418e82d7a76"><span><div id="23c6b6357e094a2da0922418e82d7a76" class="notion-header-anchor"></div><a class="notion-hash-link" href="#23c6b6357e094a2da0922418e82d7a76" title="Channel Pruning"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Channel Pruning</span></span></h4><div class="notion-text notion-block-c97427f259f34b39a942e852dd94f076"><em>For fast testing, you can directly download pruned model. See </em><a target="_blank" rel="noopener noreferrer" class="notion-link" href="about:blank#pruned-models-for-download"><em>next section</em></a> 1. Download the original VGG-16 model http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel<!-- -->
move it to <code class="notion-inline-code">temp/vgg.caffemodel</code> (or create a softlink instead)</div><ol start="1" class="notion-list notion-list-numbered notion-block-3b5b057a553a47e98c609f83b43474db"><li>Start Channel Pruning </li><ol class="notion-list notion-list-numbered notion-block-3b5b057a553a47e98c609f83b43474db"><pre class="notion-code"><code class="language-bash">python3 train.py -action c3 -caffe <span class="token punctuation">[</span>GPU0<span class="token punctuation">]</span>
 <span class="token comment"># or log it with ./run.sh python3 train.py -action c3 -caffe [GPU0]</span>
 <span class="token comment"># replace [GPU0] with actual GPU device like 0,1 or 2</span></code></pre></ol></ol><ol start="2" class="notion-list notion-list-numbered notion-block-efc40ddd9f054c398b9187ee71f2a178"><li>Combine some factorized layers for further compression, and calculate the acceleration ratio. Replace the ImageData layer of <code class="notion-inline-code">temp/cb_3c_3C4x_mem_bn_vgg.prototxt</code> with <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/blob/master/temp/vgg.prototxt#L1-L49"><code class="notion-inline-code">temp/vgg.prototxt</code></a><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/blob/master/temp/vgg.prototxt#L1-L49">’s</a> <code class="notion-inline-code">Shell ./combine.sh | xargs ./calflop.sh</code></li></ol><ol start="3" class="notion-list notion-list-numbered notion-block-ab2822c05ae64437a7d1eeadf0bc2dd7"><li>Finetuning </li><ol class="notion-list notion-list-numbered notion-block-ab2822c05ae64437a7d1eeadf0bc2dd7"><pre class="notion-code"><code class="language-bash">caffe train -solver temp/solver.prototxt -weights temp/cb_3c_vgg.caffemodel -gpu <span class="token punctuation">[</span>GPU0,GPU1,GPU2,GPU3<span class="token punctuation">]</span>
 <span class="token comment"># replace [GPU0,GPU1,GPU2,GPU3] with actual GPU device like 0,1,2,3</span></code></pre></ol></ol><ol start="4" class="notion-list notion-list-numbered notion-block-f6965c8762c347d3a9d4d706f4defcf6"><li>Testing</li><ol class="notion-list notion-list-numbered notion-block-f6965c8762c347d3a9d4d706f4defcf6"><div class="notion-text notion-block-e4e66c88dc424154be004e110c40da04">Though testing is done while finetuning, you can test anytime with: </div><pre class="notion-code"><code class="language-bash">caffe <span class="token builtin class-name">test</span> -model path/to/prototxt -weights path/to/caffemodel -iterations <span class="token number">5000</span> -gpu <span class="token punctuation">[</span>GPU0<span class="token punctuation">]</span>
 <span class="token comment"># replace [GPU0] with actual GPU device like 0,1 or 2</span></code></pre><div class="notion-text notion-block-71b838b73873449cb17b77216df57262">Pruned models (for download) </div><div class="notion-text notion-block-dc7331c77b7d4fbaac09b4196456c5d5">For fast testing, you can directly download pruned model from <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases">release</a>: <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/VGG-16_3C4x">VGG-16 3C 4X</a>, <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/channel_pruning_5x">VGG-16 5X</a>, <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/ResNet-50-2X">ResNet-50 2X</a>. Or follow Baidu Yun <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://pan.baidu.com/s/1c2evwTa">Download link</a></div></ol></ol><div class="notion-text notion-block-b903f4f59aca4d9b8bc0cb4c4a428f6f">Test with:</div><pre class="notion-code"><code class="language-plain text">caffe test <span class="token operator">-</span>model channel_pruning_VGG<span class="token operator">-</span><span class="token number">16_3</span>C4x<span class="token punctuation">.</span>prototxt <span class="token operator">-</span>weights channel_pruning_VGG<span class="token operator">-</span><span class="token number">16_3</span>C4x<span class="token punctuation">.</span>caffemodel <span class="token operator">-</span>iterations <span class="token number">5000</span> <span class="token operator">-</span>gpu <span class="token punctuation">[</span><span class="token constant">GPU0</span><span class="token punctuation">]</span>
# replace <span class="token punctuation">[</span><span class="token constant">GPU0</span><span class="token punctuation">]</span> <span class="token keyword">with</span> actual <span class="token constant">GPU</span> device like <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span> or <span class="token number">2</span></code></pre><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-86dc42ec98e64f9980bd3cc9e1ac2d3f" data-id="86dc42ec98e64f9980bd3cc9e1ac2d3f"><span><div id="86dc42ec98e64f9980bd3cc9e1ac2d3f" class="notion-header-anchor"></div><a class="notion-hash-link" href="#86dc42ec98e64f9980bd3cc9e1ac2d3f" title="Pruning faster RCNN"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Pruning faster RCNN</span></span></h4><div class="notion-text notion-block-e8592c96f98c40d1a4048a44a1e35e29">For fast testing, you can directly download pruned model from <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X">release</a>
Or you can: 1. clone my py-faster-rcnn repo: https://github.com/yihui-he/py-faster-rcnn 2. use the <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X">pruned models</a> from this repo to train faster RCNN 2X, 4X, solver prototxts are in https://github.com/yihui-he/py-faster-rcnn/tree/master/models/pascal_voc</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-46d6029766c74dd680984319b529ca17" data-id="46d6029766c74dd680984319b529ca17"><span><div id="46d6029766c74dd680984319b529ca17" class="notion-header-anchor"></div><a class="notion-hash-link" href="#46d6029766c74dd680984319b529ca17" title="FAQ"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">FAQ</span></span></h4><div class="notion-text notion-block-14a55eba7a7141dc8346871a95b7f343">You can find answers of some commonly asked questions in our <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/wiki">Github wiki</a>, or just create a <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/yihui-he/channel-pruning/issues/new">new issue</a></div></article><aside class="notion-aside"><div class="notion-aside-table-of-contents"><div class="notion-aside-table-of-contents-header">Table of Contents</div><nav class="notion-table-of-contents notion-gray"><a href="#be3df79ddf624f7ca854369a0113d0aa" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Citation</span></a><a href="#51730754003241d1bcc010a877c82a3d" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">requirements</span></a><a href="#843276d929654679a55a6fdff93cf0e4" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Installation (sufficient for the demo)</span></a><a href="#23c6b6357e094a2da0922418e82d7a76" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Channel Pruning</span></a><a href="#86dc42ec98e64f9980bd3cc9e1ac2d3f" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Pruning faster RCNN</span></a><a href="#46d6029766c74dd680984319b529ca17" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">FAQ</span></a></nav></div><div class="PageSocial_pageSocial__2WqHl"><a class="PageSocial_action__2zgVt PageSocial_twitter__-BgFt" href="https://yihui-he.github.io" title="personal website" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#000000" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path><polyline points="9 22 9 12 15 12 15 22"></polyline></svg></div></a><a class="PageSocial_action__2zgVt PageSocial_twitter__-BgFt" href="https://twitter.com/he_yi_hui" title="Twitter @he_yi_hui" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"></path></svg></div></a><a class="PageSocial_action__2zgVt PageSocial_github__slQ0z" href="https://github.com/yihui-he" title="GitHub @yihui-he" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></div></a><a class="PageSocial_action__2zgVt PageSocial_linkedin__nElHT" href="https://www.linkedin.com/in/yihui-he-a4257aab" title="LinkedIn Yihui He" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"></path></svg></div></a></div></aside></div></main><footer class="styles_footer__1r_c6"><div class="styles_copyright__3kWHj">Copyright 2022 <!-- -->Yihui He</div><div class="styles_social__235gY"><a class="styles_twitter__WwfaA" href="https://yihui-he.github.io" title="Twitter @he_yi_hui" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"></path></svg></a><a class="styles_twitter__WwfaA" href="https://twitter.com/he_yi_hui" title="Twitter @he_yi_hui" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a class="styles_github__32xIr" href="https://github.com/yihui-he" title="GitHub @yihui-he" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a class="styles_linkedin__1XGvB" href="https://www.linkedin.com/in/yihui-he-a4257aab" title="LinkedIn Yihui He" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></div></footer></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"site":{"domain":"yihui-he.github.io","name":"Yihui He","rootNotionPageId":"bd32b787e47149f38941174a9c6846b6","rootNotionSpaceId":null,"description":"Yihui He, AI research scientist / full stack engineer"},"recordMap":{"block":{"fad54c70-af5c-42a3-a00a-ff18bea9c382":{"role":"reader","value":{"id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","version":92,"type":"page","properties":{"title":[["Channel Pruning for Accelerating Very Deep Neural Networks"]]},"content":["0fe67c12-5bb4-4aec-9834-0ba7c001935d","e7a37736-20d4-4b45-bc00-4f01266c96a9","1ad84510-e4d7-42cd-b8fd-cb6a7604cb37","1e99a0fa-d687-43c6-9271-943f352d8302","982b8e1a-daac-451b-935b-3022840a10e4","791437f2-1abe-4f36-a3a5-547101a76e74","c0407ab4-7e2d-4309-9640-5f55c0d5e147","1a68fe58-b03f-4250-8ad7-43ed3441ed9d","b90ce08a-e846-474c-9299-624837df1adf","e25c4d40-d279-47c9-ab92-8e461291a95e","be3df79d-df62-4f7c-a854-369a0113d0aa","f42bf102-ce2f-400f-9f57-e3c7f4be2be9","bdef0568-6a59-40b0-b803-b8313058a84e","51730754-0032-41d1-bcc0-10a877c82a3d","76a535f3-2882-43e3-862e-e39b1e3cccf8","049d4b64-1f40-4de6-a23b-0d25df0efd5e","843276d9-2965-4679-a55a-6fdff93cf0e4","8e238688-b248-4584-9d7b-0044735e3956","ee16fc17-3c37-4749-9ddf-cbcf8f8d3dfe","bdbd1e87-a99a-4ada-a123-4471294cdb7f","b4caea59-9ccc-4b9f-b8f8-283793755973","23c6b635-7e09-4a2d-a092-2418e82d7a76","c97427f2-59f3-4b39-a942-e852dd94f076","3b5b057a-553a-47e9-8c60-9f83b43474db","efc40ddd-9f05-4c39-8b91-87ee71f2a178","ab2822c0-5ae6-4437-a7d1-eeadf0bc2dd7","f6965c87-62c3-47d3-a9d4-d706f4defcf6","b903f4f5-9aca-4d9b-8bc0-cb4c4a428f6f","6c1f166d-d830-4f90-b277-3b94004b2a19","86dc42ec-98e6-4f99-80bd-3cc9e1ac2d3f","e8592c96-f98c-40d1-a404-8a44a1e35e29","46d60297-66c7-4dd6-8098-4319b529ca17","14a55eba-7a71-41dc-8346-871a95b7f343"],"permissions":[{"role":"editor","type":"user_permission","user_id":"9e9c4442-4350-473a-b900-c954b0bd7a95"}],"created_time":1645431973644,"last_edited_time":1645646640000,"parent_id":"bd32b787-e471-49f3-8941-174a9c6846b6","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bd32b787-e471-49f3-8941-174a9c6846b6":{"role":"reader","value":{"id":"bd32b787-e471-49f3-8941-174a9c6846b6","version":263,"type":"page","properties":{"title":[["Yihui He’s Blog"]]},"content":["cc62526f-e4eb-42e5-8e8f-a22c3abd7b46","eb534ff0-d0e6-4c83-b817-92c761ad9034","41249f3f-76a2-458a-b13d-2bc06310337b","09ac442d-d3b5-4f43-9531-90cdae7640b7","76f263cc-0736-4657-91dd-551b1c541b4c","fad54c70-af5c-42a3-a00a-ff18bea9c382","9abe926f-8b36-4a60-a77e-e5436690a8c0","84c674a7-bbe3-4ac5-88c7-68e0c3909585","09517098-a843-437e-bb7a-4ac67866b29b","e7a12f56-b48c-43bf-803e-96d70518685f","932f5707-ab83-4542-af11-68fec7b5f28d","e6311219-0ef8-4142-8a3f-eeedc910dd3b","5f16dda4-316e-43af-a4ea-8fc6d6938404","23859d82-2201-4bb6-a86a-db693ea4992a","d5a94597-8cb4-43be-a6d0-0840b5518710","c54caf49-d28c-46ac-b72d-fc9bfa58bbdd","4751172a-1cb9-4633-84d6-21ba334ee3d7","8e23ed11-04f5-48ab-a95d-1f47a5cd22af","4b2fb8ba-1e4c-47ff-903b-0869360db746","010faf71-b9e5-4c47-832a-658dafc6e7ae","3db8e8fd-7383-4aea-8beb-608282db050e","60ff1c6d-fde5-426d-ac57-7bba2a5296a2","31008559-3d6f-4c33-bb50-4e463c9b19fb","201efca9-ba21-47c3-8b0d-35b41dd3f91f","04ced6eb-ca82-46db-8f8e-077f3bf6b29c","daf31581-086b-4fb1-9695-5a79117d4300","a0487f2c-eed0-4154-a6e8-2366ca1d7939","95728d67-dc1f-4086-881b-1cd1bf72f985","cba2b20a-aa13-466c-bcb6-a9f9c9f057da","5e0b979d-ef00-44a3-894f-38d28cfd7576","38a364d6-720a-4788-aeee-c2b224745860","6a838606-233d-4584-b2f1-3d198b1603e8","f93f1e88-d826-4cd3-ab2a-cd92ddd2ac53","e8156bf2-5303-4590-a44a-6db1404c8c7b","2411768d-af34-4f88-8772-c46ca4428256","52357a78-3241-4a0a-bcb7-46bfd15070a4","3f4c64fb-75dc-4ccd-9e22-ce5704d0dfdb","d1ef1d4d-bfa8-40c4-a78c-037da96f3681"],"discussions":["a13be18e-5008-4f8c-b07a-0fadb99d7450"],"format":{"page_icon":"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/63e89fe9-f5cd-4414-be0e-53d91aa54fc3/me_small.jpg"},"permissions":[{"role":"editor","type":"user_permission","user_id":"9e9c4442-4350-473a-b900-c954b0bd7a95"},{"role":"reader","type":"public_permission","added_timestamp":1645466303668}],"created_time":1645422720000,"last_edited_time":1646017200000,"parent_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1","parent_table":"space","alive":true,"file_ids":["e3d85759-49f2-40d2-ba30-d25ca401872e","cfc564cc-91ae-4a96-a912-fcc9a28ec5db","63e89fe9-f5cd-4414-be0e-53d91aa54fc3"],"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"0fe67c12-5bb4-4aec-9834-0ba7c001935d":{"role":"reader","value":{"id":"0fe67c12-5bb4-4aec-9834-0ba7c001935d","version":7,"type":"bookmark","properties":{"link":[["https://github.com/yihui-he/channel-pruning"]],"title":[["GitHub - yihui-he/channel-pruning: Channel Pruning for Accelerating Very Deep Neural Networks (ICCV'17)"]],"description":[["You can't perform that action at this time. You signed in with another tab or window. You signed out in another tab or window. Reload to refresh your session. Reload to refresh your session."]]},"format":{"bookmark_icon":"https://github.com/favicon.ico","bookmark_cover":"https://repository-images.githubusercontent.com/100935205/1d782480-e3a6-11e9-935b-3e5a7f46040e"},"created_time":1645646665129,"last_edited_by":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_time":1645646640000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e7a37736-20d4-4b45-bc00-4f01266c96a9":{"role":"reader","value":{"id":"e7a37736-20d4-4b45-bc00-4f01266c96a9","version":9,"type":"bookmark","properties":{"link":[["https://arxiv.org/abs/1707.06168"]],"title":[["Channel Pruning for Accelerating Very Deep Neural Networks"]],"description":[["In this paper, we introduce a new channel pruning method to accelerate very deep convolutional neural networks.Given a trained CNN model, we propose an iterative two-step algorithm to effectively prune each layer, by a LASSO regression based channel selection and least square reconstruction. We further generalize this algorithm to multi-layer and multi-branch cases."]]},"format":{"bookmark_icon":"https://static.arxiv.org/static/browse/0.3.3/images/icons/favicon.ico","bookmark_cover":"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"},"created_time":1645433820000,"last_edited_time":1645433820000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"1ad84510-e4d7-42cd-b8fd-cb6a7604cb37":{"role":"reader","value":{"id":"1ad84510-e4d7-42cd-b8fd-cb6a7604cb37","version":3,"type":"text","properties":{"title":[["ICCV 2017",[["b"]]],[", by "],["Yihui He",[["a","http://yihui-he.github.io/"]]],[", "],["Xiangyu Zhang",[["a","https://scholar.google.com/citations?user=yuB-cfoAAAAJ\u0026hl=en\u0026oi=ao"]]],[" and "],["Jian Sun",[["a","http://jiansun.org/"]]]]},"created_time":1645431973404,"last_edited_time":1645433820000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"1e99a0fa-d687-43c6-9271-943f352d8302":{"role":"reader","value":{"id":"1e99a0fa-d687-43c6-9271-943f352d8302","version":3,"type":"text","properties":{"title":[["Please have a look our new works on compressing deep models: "]]},"created_time":1645431973413,"last_edited_time":1645433340000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"982b8e1a-daac-451b-935b-3022840a10e4":{"role":"reader","value":{"id":"982b8e1a-daac-451b-935b-3022840a10e4","version":16,"type":"bulleted_list","properties":{"title":[["AMC: AutoML for Model Compression and Acceleration on Mobile Devices",[["a","http://openaccess.thecvf.com/content_ECCV_2018/html/Yihui_He_AMC_Automated_Model_ECCV_2018_paper.html"]]],[" "],["ECCV’18",[["b"]]],[", which combines channel pruning and reinforcement learning to further accelerate CNN. "],["code",[["a","https://github.com/mit-han-lab/amc-release"]]],[" and "],["models",[["a","https://github.com/mit-han-lab/amc-compressed-models"]]],[" are available! "]]},"created_time":1645433340000,"last_edited_time":1645433400000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"791437f2-1abe-4f36-a3a5-547101a76e74":{"role":"reader","value":{"id":"791437f2-1abe-4f36-a3a5-547101a76e74","version":7,"type":"bulleted_list","properties":{"title":[["AddressNet: Shift-Based Primitives for Efficient Convolutional Neural Networks",[["a","https://arxiv.org/abs/1809.08458"]]],[" "],["WACV’19",[["b"]]],[". We propose a family of efficient networks based on Shift operation. "]]},"created_time":1645433400000,"last_edited_time":1645433400000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"c0407ab4-7e2d-4309-9640-5f55c0d5e147":{"role":"reader","value":{"id":"c0407ab4-7e2d-4309-9640-5f55c0d5e147","version":4,"type":"bulleted_list","properties":{"title":[["MoBiNet: A Mobile Binary Network for Image Classification",[["a","https://arxiv.org/abs/1907.12629"]]],[" "],["WACV’20",[["b"]]],[" Binarized MobileNets."]]},"created_time":1645433400000,"last_edited_time":1645433400000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"1a68fe58-b03f-4250-8ad7-43ed3441ed9d":{"role":"reader","value":{"id":"1a68fe58-b03f-4250-8ad7-43ed3441ed9d","version":1,"type":"text","properties":{"title":[["In this repository, we released code for the following models:"]]},"created_time":1645431973414,"last_edited_time":1645431973414,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b90ce08a-e846-474c-9299-624837df1adf":{"role":"reader","value":{"id":"b90ce08a-e846-474c-9299-624837df1adf","version":1,"type":"collection_view","view_ids":["891c327f-de15-49f6-a92a-34054d1f585a"],"collection_id":"25194445-f310-4498-9307-16d2980acd25","format":{"collection_pointer":{"id":"25194445-f310-4498-9307-16d2980acd25","table":"collection","spaceId":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"created_time":1645431973575,"last_edited_time":1645431973575,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e25c4d40-d279-47c9-ab92-8e461291a95e":{"role":"reader","value":{"id":"e25c4d40-d279-47c9-ab92-8e461291a95e","version":6,"type":"text","properties":{"title":[["3C method combined spatial decomposition ("],["Speeding up Convolutional Neural Networks with Low Rank Expansions",[["a","https://arxiv.org/abs/1405.3866"]]],[") and channel decomposition ("],["Accelerating Very Deep Convolutional Networks for Classification and Detection",[["a","https://arxiv.org/abs/1505.06798"]]],[") (mentioned in 4.1.2)"]]},"created_time":1645431973578,"last_edited_time":1645433460000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"be3df79d-df62-4f7c-a854-369a0113d0aa":{"role":"reader","value":{"id":"be3df79d-df62-4f7c-a854-369a0113d0aa","version":1,"type":"sub_sub_header","properties":{"title":[["Citation"]]},"created_time":1645431973606,"last_edited_time":1645431973606,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"f42bf102-ce2f-400f-9f57-e3c7f4be2be9":{"role":"reader","value":{"id":"f42bf102-ce2f-400f-9f57-e3c7f4be2be9","version":1,"type":"text","properties":{"title":[["If you find the code useful in your research, please consider citing:"]]},"created_time":1645431973606,"last_edited_time":1645431973606,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bdef0568-6a59-40b0-b803-b8313058a84e":{"role":"reader","value":{"id":"bdef0568-6a59-40b0-b803-b8313058a84e","version":3,"type":"code","properties":{"title":[["@InProceedings{He_2017_ICCV,\nauthor = {He, Yihui and Zhang, Xiangyu and Sun, Jian},\ntitle = {Channel Pruning for Accelerating Very Deep Neural Networks},\nbooktitle = {The IEEE International Conference on Computer Vision (ICCV)},\nmonth = {Oct},\nyear = {2017}\n}"]],"language":[["Plain Text"]]},"format":{"code_wrap":true},"created_time":1645431973607,"last_edited_time":1645433760000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"51730754-0032-41d1-bcc0-10a877c82a3d":{"role":"reader","value":{"id":"51730754-0032-41d1-bcc0-10a877c82a3d","version":1,"type":"sub_sub_header","properties":{"title":[["requirements"]]},"created_time":1645431973617,"last_edited_time":1645431973617,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"76a535f3-2882-43e3-862e-e39b1e3cccf8":{"role":"reader","value":{"id":"76a535f3-2882-43e3-862e-e39b1e3cccf8","version":1,"type":"numbered_list","properties":{"title":[["Python3 packages you might not have: "],["scipy",[["c"]]],[", "],["sklearn",[["c"]]],[", "],["easydict",[["c"]]],[", use "],["sudo pip3 install",[["c"]]],[" to install."]]},"created_time":1645431973619,"last_edited_time":1645431973619,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"049d4b64-1f40-4de6-a23b-0d25df0efd5e":{"role":"reader","value":{"id":"049d4b64-1f40-4de6-a23b-0d25df0efd5e","version":1,"type":"numbered_list","properties":{"title":[["For finetuning with 128 batch size, 4 GPUs (~11G of memory)"]]},"created_time":1645431973619,"last_edited_time":1645431973619,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"843276d9-2965-4679-a55a-6fdff93cf0e4":{"role":"reader","value":{"id":"843276d9-2965-4679-a55a-6fdff93cf0e4","version":1,"type":"sub_sub_header","properties":{"title":[["Installation (sufficient for the demo)"]]},"created_time":1645431973620,"last_edited_time":1645431973620,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"8e238688-b248-4584-9d7b-0044735e3956":{"role":"reader","value":{"id":"8e238688-b248-4584-9d7b-0044735e3956","version":7,"type":"numbered_list","properties":{"title":[["Clone the repository"]]},"content":["dbbcd4c1-acea-414c-92aa-43e6918e741c"],"created_time":1645431973620,"last_edited_time":1645433880000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"dbbcd4c1-acea-414c-92aa-43e6918e741c":{"role":"reader","value":{"id":"dbbcd4c1-acea-414c-92aa-43e6918e741c","version":7,"type":"code","properties":{"title":[["# Make sure to clone with --recursive\n git clone --recursive https://github.com/yihui-he/channel-pruning.git"]],"language":[["Bash"]]},"format":{"code_wrap":true},"created_time":1645433937035,"last_edited_by":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_time":1645433940000,"parent_id":"8e238688-b248-4584-9d7b-0044735e3956","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ee16fc17-3c37-4749-9ddf-cbcf8f8d3dfe":{"role":"reader","value":{"id":"ee16fc17-3c37-4749-9ddf-cbcf8f8d3dfe","version":7,"type":"numbered_list","properties":{"title":[["Build "],["my Caffe",[["a","https://github.com/yihui-he/caffe-pro"]]],[" fork (which support bicubic interpolation and resizing image shorter side to 256 then crop to 224x224) "]]},"content":["190d7627-0d97-4e00-82f7-cec2135d7e9c"],"created_time":1645431973622,"last_edited_time":1645433640000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"190d7627-0d97-4e00-82f7-cec2135d7e9c":{"role":"reader","value":{"id":"190d7627-0d97-4e00-82f7-cec2135d7e9c","version":14,"type":"code","properties":{"title":[["cd caffe\n\n # If you're experienced with Caffe and have all of the requirements installed, then simply do:\n make all -j8 \u0026\u0026 make pycaffe\n # Or follow the Caffe installation instructions here:\n # http://caffe.berkeleyvision.org/installation.html\n\n # you might need to add pycaffe to PYTHONPATH, if you've already had a caffe before"]],"language":[["Bash"]]},"format":{"code_wrap":true},"created_time":1645433580000,"last_edited_time":1645433640000,"parent_id":"ee16fc17-3c37-4749-9ddf-cbcf8f8d3dfe","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bdbd1e87-a99a-4ada-a123-4471294cdb7f":{"role":"reader","value":{"id":"bdbd1e87-a99a-4ada-a123-4471294cdb7f","version":1,"type":"numbered_list","properties":{"title":[["Download ImageNet classification dataset http://www.image-net.org/download-images"]]},"created_time":1645431973623,"last_edited_time":1645431973623,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b4caea59-9ccc-4b9f-b8f8-283793755973":{"role":"reader","value":{"id":"b4caea59-9ccc-4b9f-b8f8-283793755973","version":1,"type":"numbered_list","properties":{"title":[["Specify imagenet "],["source",[["c"]]],[" path in "],["temp/vgg.prototxt",[["c"]]],[" (line 12 and 36)"]]},"created_time":1645431973624,"last_edited_time":1645431973624,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"23c6b635-7e09-4a2d-a092-2418e82d7a76":{"role":"reader","value":{"id":"23c6b635-7e09-4a2d-a092-2418e82d7a76","version":1,"type":"sub_sub_header","properties":{"title":[["Channel Pruning"]]},"created_time":1645431973624,"last_edited_time":1645431973624,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"c97427f2-59f3-4b39-a942-e852dd94f076":{"role":"reader","value":{"id":"c97427f2-59f3-4b39-a942-e852dd94f076","version":1,"type":"text","properties":{"title":[["For fast testing, you can directly download pruned model. See ",[["i"]]],["next section",[["i"],["a","about:blank#pruned-models-for-download"]]],[" 1. Download the original VGG-16 model http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel"],["\nmove it to "],["temp/vgg.caffemodel",[["c"]]],[" (or create a softlink instead)"]]},"created_time":1645431973625,"last_edited_time":1645431973625,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"3b5b057a-553a-47e9-8c60-9f83b43474db":{"role":"reader","value":{"id":"3b5b057a-553a-47e9-8c60-9f83b43474db","version":7,"type":"numbered_list","properties":{"title":[["Start Channel Pruning "]]},"content":["1803a382-128e-422c-a0a8-ec753a7062e5"],"created_time":1645431973626,"last_edited_time":1645433640000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"1803a382-128e-422c-a0a8-ec753a7062e5":{"role":"reader","value":{"id":"1803a382-128e-422c-a0a8-ec753a7062e5","version":7,"type":"code","properties":{"title":[["python3 train.py -action c3 -caffe [GPU0]\n # or log it with ./run.sh python3 train.py -action c3 -caffe [GPU0]\n # replace [GPU0] with actual GPU device like 0,1 or 2"]],"language":[["Bash"]]},"format":{"code_wrap":true},"created_time":1645433694433,"last_edited_by":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_time":1645433700000,"parent_id":"3b5b057a-553a-47e9-8c60-9f83b43474db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"efc40ddd-9f05-4c39-8b91-87ee71f2a178":{"role":"reader","value":{"id":"efc40ddd-9f05-4c39-8b91-87ee71f2a178","version":1,"type":"numbered_list","properties":{"title":[["Combine some factorized layers for further compression, and calculate the acceleration ratio. Replace the ImageData layer of "],["temp/cb_3c_3C4x_mem_bn_vgg.prototxt",[["c"]]],[" with "],["temp/vgg.prototxt",[["c"],["a","https://github.com/yihui-he/channel-pruning/blob/master/temp/vgg.prototxt#L1-L49"]]],["’s",[["a","https://github.com/yihui-he/channel-pruning/blob/master/temp/vgg.prototxt#L1-L49"]]],[" "],["Shell ./combine.sh | xargs ./calflop.sh",[["c"]]]]},"created_time":1645431973628,"last_edited_time":1645431973628,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ab2822c0-5ae6-4437-a7d1-eeadf0bc2dd7":{"role":"reader","value":{"id":"ab2822c0-5ae6-4437-a7d1-eeadf0bc2dd7","version":6,"type":"numbered_list","properties":{"title":[["Finetuning "]]},"content":["6e808acc-bb31-466b-a3e2-4d747bf3b1e2"],"created_time":1645431973628,"last_edited_time":1645433940000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6e808acc-bb31-466b-a3e2-4d747bf3b1e2":{"role":"reader","value":{"id":"6e808acc-bb31-466b-a3e2-4d747bf3b1e2","version":6,"type":"code","properties":{"title":[["caffe train -solver temp/solver.prototxt -weights temp/cb_3c_vgg.caffemodel -gpu [GPU0,GPU1,GPU2,GPU3]\n # replace [GPU0,GPU1,GPU2,GPU3] with actual GPU device like 0,1,2,3"]],"language":[["Bash"]]},"format":{"code_wrap":true},"created_time":1645433962568,"last_edited_by":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_time":1645433940000,"parent_id":"ab2822c0-5ae6-4437-a7d1-eeadf0bc2dd7","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"f6965c87-62c3-47d3-a9d4-d706f4defcf6":{"role":"reader","value":{"id":"f6965c87-62c3-47d3-a9d4-d706f4defcf6","version":15,"type":"numbered_list","properties":{"title":[["Testing"]]},"content":["e4e66c88-dc42-4154-be00-4e110c40da04","a7818e1c-27a1-4925-9185-6203fe897181","71b838b7-3873-449c-b17b-77216df57262","dc7331c7-7b7d-4fba-ac09-b4196456c5d5"],"created_time":1645431973636,"last_edited_time":1645433940000,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e4e66c88-dc42-4154-be00-4e110c40da04":{"role":"reader","value":{"id":"e4e66c88-dc42-4154-be00-4e110c40da04","version":13,"type":"text","properties":{"title":[["Though testing is done while finetuning, you can test anytime with: "]]},"created_time":1645431973635,"last_edited_time":1645433940000,"parent_id":"f6965c87-62c3-47d3-a9d4-d706f4defcf6","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a7818e1c-27a1-4925-9185-6203fe897181":{"role":"reader","value":{"id":"a7818e1c-27a1-4925-9185-6203fe897181","version":6,"type":"code","properties":{"title":[["caffe test -model path/to/prototxt -weights path/to/caffemodel -iterations 5000 -gpu [GPU0]\n # replace [GPU0] with actual GPU device like 0,1 or 2"]],"language":[["Bash"]]},"format":{"code_wrap":true},"created_time":1645433977754,"last_edited_by":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_time":1645433940000,"parent_id":"f6965c87-62c3-47d3-a9d4-d706f4defcf6","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"71b838b7-3873-449c-b17b-77216df57262":{"role":"reader","value":{"id":"71b838b7-3873-449c-b17b-77216df57262","version":24,"type":"text","properties":{"title":[["Pruned models (for download) "]]},"created_time":1645433700000,"last_edited_time":1645433700000,"parent_id":"f6965c87-62c3-47d3-a9d4-d706f4defcf6","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"dc7331c7-7b7d-4fba-ac09-b4196456c5d5":{"role":"reader","value":{"id":"dc7331c7-7b7d-4fba-ac09-b4196456c5d5","version":4,"type":"text","properties":{"title":[["For fast testing, you can directly download pruned model from "],["release",[["a","https://github.com/yihui-he/channel-pruning/releases"]]],[": "],["VGG-16 3C 4X",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/VGG-16_3C4x"]]],[", "],["VGG-16 5X",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/channel_pruning_5x"]]],[", "],["ResNet-50 2X",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/ResNet-50-2X"]]],[". Or follow Baidu Yun "],["Download link",[["a","https://pan.baidu.com/s/1c2evwTa"]]]]},"created_time":1645433700000,"last_edited_time":1645433700000,"parent_id":"f6965c87-62c3-47d3-a9d4-d706f4defcf6","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b903f4f5-9aca-4d9b-8bc0-cb4c4a428f6f":{"role":"reader","value":{"id":"b903f4f5-9aca-4d9b-8bc0-cb4c4a428f6f","version":1,"type":"text","properties":{"title":[["Test with:"]]},"created_time":1645431973636,"last_edited_time":1645431973636,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6c1f166d-d830-4f90-b277-3b94004b2a19":{"role":"reader","value":{"id":"6c1f166d-d830-4f90-b277-3b94004b2a19","version":1,"type":"code","properties":{"title":[["caffe test -model channel_pruning_VGG-16_3C4x.prototxt -weights channel_pruning_VGG-16_3C4x.caffemodel -iterations 5000 -gpu [GPU0]\n# replace [GPU0] with actual GPU device like 0,1 or 2"]],"language":[["Plain Text"]]},"format":{"code_wrap":true},"created_time":1645431973637,"last_edited_time":1645431973637,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"86dc42ec-98e6-4f99-80bd-3cc9e1ac2d3f":{"role":"reader","value":{"id":"86dc42ec-98e6-4f99-80bd-3cc9e1ac2d3f","version":1,"type":"sub_sub_header","properties":{"title":[["Pruning faster RCNN"]]},"created_time":1645431973637,"last_edited_time":1645431973637,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e8592c96-f98c-40d1-a404-8a44a1e35e29":{"role":"reader","value":{"id":"e8592c96-f98c-40d1-a404-8a44a1e35e29","version":1,"type":"text","properties":{"title":[["For fast testing, you can directly download pruned model from "],["release",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X"]]],["\nOr you can: 1. clone my py-faster-rcnn repo: https://github.com/yihui-he/py-faster-rcnn 2. use the "],["pruned models",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X"]]],[" from this repo to train faster RCNN 2X, 4X, solver prototxts are in https://github.com/yihui-he/py-faster-rcnn/tree/master/models/pascal_voc"]]},"created_time":1645431973641,"last_edited_time":1645431973641,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"46d60297-66c7-4dd6-8098-4319b529ca17":{"role":"reader","value":{"id":"46d60297-66c7-4dd6-8098-4319b529ca17","version":1,"type":"sub_sub_header","properties":{"title":[["FAQ"]]},"created_time":1645431973642,"last_edited_time":1645431973642,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"14a55eba-7a71-41dc-8346-871a95b7f343":{"role":"reader","value":{"id":"14a55eba-7a71-41dc-8346-871a95b7f343","version":1,"type":"text","properties":{"title":[["You can find answers of some commonly asked questions in our "],["Github wiki",[["a","https://github.com/yihui-he/channel-pruning/wiki"]]],[", or just create a "],["new issue",[["a","https://github.com/yihui-he/channel-pruning/issues/new"]]]]},"created_time":1645431973644,"last_edited_time":1645431973644,"parent_id":"fad54c70-af5c-42a3-a00a-ff18bea9c382","parent_table":"block","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"37f57449-1731-4a90-afd4-39f15077206f":{"role":"reader","value":{"id":"37f57449-1731-4a90-afd4-39f15077206f","version":1,"type":"page","properties":{"V[@j":[["88.1 (Top-5), 67.8 (Top-1)"]],"w|GL":[["VGG-16 channel pruning",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/channel_pruning_5x"]]]],"title":[["5x"]]},"created_time":1645431973575,"last_edited_time":1645431973575,"parent_id":"25194445-f310-4498-9307-16d2980acd25","parent_table":"collection","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b4109b28-fd2b-42a9-8607-69db23effa59":{"role":"reader","value":{"id":"b4109b28-fd2b-42a9-8607-69db23effa59","version":1,"type":"page","properties":{"V[@j":[["36.7 (AP@.50:.05:.95)"]],"w|GL":[["faster RCNN",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X"]]]],"title":[["2x"]]},"created_time":1645431973575,"last_edited_time":1645431973575,"parent_id":"25194445-f310-4498-9307-16d2980acd25","parent_table":"collection","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"712dc1cd-e775-40eb-86d2-60f1784480b2":{"role":"reader","value":{"id":"712dc1cd-e775-40eb-86d2-60f1784480b2","version":3,"type":"page","properties":{"V[@j":[["89.9 (Top-5), 70.6 (Top-1)"]],"w|GL":[["VGG-16 3C",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/VGG-16_3C4x"]]]],"title":[["4x"]]},"created_time":1645431973575,"last_edited_time":1645433460000,"parent_id":"25194445-f310-4498-9307-16d2980acd25","parent_table":"collection","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"f86fa2e6-2ded-4074-ade9-2b6a9b6c912b":{"role":"reader","value":{"id":"f86fa2e6-2ded-4074-ade9-2b6a9b6c912b","version":1,"type":"page","properties":{"V[@j":[["90.8 (Top-5), 72.3 (Top-1)"]],"w|GL":[["ResNet-50",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/ResNet-50-2X"]]]],"title":[["2x"]]},"created_time":1645431973575,"last_edited_time":1645431973575,"parent_id":"25194445-f310-4498-9307-16d2980acd25","parent_table":"collection","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6d0faf88-d1f7-47b4-ad59-882b6e760cf8":{"role":"reader","value":{"id":"6d0faf88-d1f7-47b4-ad59-882b6e760cf8","version":1,"type":"page","properties":{"V[@j":[["35.1 (AP@.50:.05:.95)"]],"w|GL":[["faster RCNN",[["a","https://github.com/yihui-he/channel-pruning/releases/tag/faster-RCNN-2X4X"]]]],"title":[["4x"]]},"created_time":1645431973575,"last_edited_time":1645431973575,"parent_id":"25194445-f310-4498-9307-16d2980acd25","parent_table":"collection","alive":true,"ignore_block_count":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}}},"space":{},"discussion":{},"comment":{},"collection_view":{"891c327f-de15-49f6-a92a-34054d1f585a":{"role":"reader","value":{"id":"891c327f-de15-49f6-a92a-34054d1f585a","version":1,"type":"table","name":"Show All","format":{"table_wrap":true,"table_properties":[{"visible":true,"property":"w|GL"},{"visible":true,"property":"title"},{"visible":true,"property":"V[@j"}]},"parent_id":"b90ce08a-e846-474c-9299-624837df1adf","parent_table":"block","alive":true,"page_sort":["37f57449-1731-4a90-afd4-39f15077206f","712dc1cd-e775-40eb-86d2-60f1784480b2","f86fa2e6-2ded-4074-ade9-2b6a9b6c912b","b4109b28-fd2b-42a9-8607-69db23effa59","6d0faf88-d1f7-47b4-ad59-882b6e760cf8"],"space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}}},"collection":{"25194445-f310-4498-9307-16d2980acd25":{"role":"reader","value":{"id":"25194445-f310-4498-9307-16d2980acd25","version":1,"schema":{"V[@j":{"name":"Accuracy","type":"text"},"w|GL":{"name":"model","type":"text"},"title":{"name":"Speed-up","type":"title"}},"parent_id":"b90ce08a-e846-474c-9299-624837df1adf","parent_table":"block","alive":true,"migrated":true,"space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}}},"notion_user":{},"collection_query":{"25194445-f310-4498-9307-16d2980acd25":{"891c327f-de15-49f6-a92a-34054d1f585a":{"type":"results","blockIds":["37f57449-1731-4a90-afd4-39f15077206f","712dc1cd-e775-40eb-86d2-60f1784480b2","f86fa2e6-2ded-4074-ade9-2b6a9b6c912b","b4109b28-fd2b-42a9-8607-69db23effa59","6d0faf88-d1f7-47b4-ad59-882b6e760cf8"],"hasMore":false}}},"signed_urls":{},"preview_images":{}},"pageId":"fad54c70-af5c-42a3-a00a-ff18bea9c382"},"__N_SSG":true},"page":"/[pageId]","query":{"pageId":"channel-pruning-for-accelerating-very-deep-neural-networks"},"buildId":"wS-AqNTKr-7sWPE_cAUmu","assetPrefix":"/blog","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>