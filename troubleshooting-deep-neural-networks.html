<!DOCTYPE html><html lang="en"><head><link rel="shortcut icon" href="/favicon.png"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/manifest.json"/><meta charSet="utf-8"/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta property="og:description" content="Yihui He, AI research scientist / full stack engineer"/><meta name="theme-color" content="#EB625A"/><meta property="og:type" content="website"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4253216309174736" crossorigin="anonymous"></script><meta property="og:title" content="Troubleshooting Deep Neural Networks"/><meta property="og:site_name" content="Yihui He"/><meta name="twitter:title" content="Troubleshooting Deep Neural Networks"/><meta property="twitter:domain" content="yihui-he.github.io"/><meta name="twitter:creator" content="@he_yi_hui"/><meta name="description" content="Yihui He, AI research scientist / full stack engineer"/><meta property="og:description" content="Yihui He, AI research scientist / full stack engineer"/><meta name="twitter:description" content="Yihui He, AI research scientist / full stack engineer"/><meta name="twitter:card" content="summary"/><link rel="canonical" href="https://yihui-he.github.io/troubleshooting-deep-neural-networks"/><meta property="og:url" content="https://yihui-he.github.io/troubleshooting-deep-neural-networks"/><meta property="twitter:url" content="https://yihui-he.github.io/troubleshooting-deep-neural-networks"/><title>Troubleshooting Deep Neural Networks</title><meta name="next-head-count" content="20"/><link rel="preload" href="/blog/_next/static/css/65d691ce4d9328bfefea.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/65d691ce4d9328bfefea.css" data-n-g=""/><link rel="preload" href="/blog/_next/static/css/4b67152b49ef8d389eef.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/4b67152b49ef8d389eef.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/blog/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/blog/_next/static/chunks/webpack-ac2aaa5a7a1baa4824dd.js" defer=""></script><script src="/blog/_next/static/chunks/framework-c93ed74a065331c4bd75.js" defer=""></script><script src="/blog/_next/static/chunks/main-0989120ac94443065aa9.js" defer=""></script><script src="/blog/_next/static/chunks/pages/_app-83dcda1b46ac230db613.js" defer=""></script><script src="/blog/_next/static/chunks/1bfc9850-762e4e08544c8bec659c.js" defer=""></script><script src="/blog/_next/static/chunks/ae51ba48-7f31b5cf321fe3268476.js" defer=""></script><script src="/blog/_next/static/chunks/d7eeaac4-07e2c37279f27c6f41bc.js" defer=""></script><script src="/blog/_next/static/chunks/875-291d2103666b9d9c5329.js" defer=""></script><script src="/blog/_next/static/chunks/270-af0310cd9339a905b705.js" defer=""></script><script src="/blog/_next/static/chunks/pages/%5BpageId%5D-c63ce9df319d103b914e.js" defer=""></script><script src="/blog/_next/static/9poW2wwFjweYMtUtYyNUe/_buildManifest.js" defer=""></script><script src="/blog/_next/static/9poW2wwFjweYMtUtYyNUe/_ssgManifest.js" defer=""></script></head><body><script src="noflash.js"></script><div id="__next"><div class="notion notion-app light-mode notion-block-94cea945881b4d6bbe5c505834b715db"><div class="notion-viewport"></div><div class="notion-frame"><header class="notion-header"><div class="nav-header"><div class="breadcrumbs"><a class="breadcrumb" href="/blog"><img class="icon notion-page-icon" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F63e89fe9-f5cd-4414-be0e-53d91aa54fc3%2Fme_small.jpg?table=block&amp;id=bd32b787-e471-49f3-8941-174a9c6846b6&amp;cache=v2" alt="Yihui He’s Blog" loading="lazy"/><span class="title">Yihui He’s Blog</span></a><span class="spacer">/</span><a class="breadcrumb" href="/blog/deep-learning-engineer-manual"><span class="title">deep learning engineer manual</span></a><span class="spacer">/</span><div class="breadcrumb active"><span class="title">Troubleshooting Deep Neural Networks</span></div></div><div class="rhs"></div></div></header><div class="notion-page-scroller"><main class="notion-page notion-page-no-cover notion-page-no-icon notion-page-has-text-icon notion-full-page"><h1 class="notion-title"><b>Troubleshooting Deep Neural Networks</b></h1><div class="notion-page-content notion-page-content-has-aside notion-page-content-has-toc"><article class="notion-page-content-inner"><div class="notion-text notion-block-c24004dbf73b44e5b8fa44ebcf22447a">In traditional software engineering, a bug usually leads to the program crashing. While this is annoying for the user, it is critical for the developer to inspect the errors to understand why. With deep learning, we sometimes encounter errors, but all too often, the program crashes without a clear reason why. While these issues can be debugged manually, deep learning models most often fail because of poor output predictions. What’s worse is that when the model performance is low, there is usually no signal about why or when the models failed.</div><div class="notion-text notion-block-6723210b5c9840adb4792473a93ea4be">A common sentiment among practitioners is that they spend <b>80–90% of time debugging and tuning the models</b> and only 10–20% of time deriving math equations and implementing things. This is confirmed by Andrej Kaparthy, <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://twitter.com/karpathy/status/423990618289733632"><span class="notion-inline-underscore"><b>as seen in this tweet</b></span></a>.</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-68839e035ecf47ee9ed4cceb22350031" data-id="68839e035ecf47ee9ed4cceb22350031"><span><div id="68839e035ecf47ee9ed4cceb22350031" class="notion-header-anchor"></div><a class="notion-hash-link" href="#68839e035ecf47ee9ed4cceb22350031" title="1 - Why Is Deep Learning Troubleshooting Hard?"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">1 - Why Is Deep Learning Troubleshooting Hard?</span></span></h4><div class="notion-text notion-block-6c1553da9d244e84b38606f7e53c4c19">Suppose you are trying to reproduce a research paper result for your work, but your results are worse. You might wonder why your model’s performance is significantly worse than the paper that you’re trying to reproduce?</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-39a7abdeb07d44368dae4f48261a582a"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage3.png?table=block&amp;id=39a7abde-b07d-4436-8dae-4f48261a582a&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><div class="notion-text notion-block-54e72d65b5db49d3bd4026e623712f6d">Many different things can cause this:</div><ul class="notion-list notion-list-disc notion-block-7b51d6b538b54fe499d65ee9bcddb8ca"><li>It can be <b>implementation bugs</b>. Most bugs in deep learning are actually invisible.</li></ul><ul class="notion-list notion-list-disc notion-block-2288e49deac94238a3ed953c8ed31067"><li><b>Hyper-parameter choices</b> can also cause your performance to degrade. Deep learning models are very sensitive to hyper-parameters. Even very subtle choices of learning rate and weight initialization can make a big difference.</li></ul><ul class="notion-list notion-list-disc notion-block-15662054e89e468f927f2e21471fb714"><li>Performance can also be worse just because of <b>data/model fit</b>. For example, you pre-train your model on ImageNet data and fit it on self-driving car images, which are harder to learn.</li></ul><ul class="notion-list notion-list-disc notion-block-dd3420ddf5ca47c2b331dbd41e5a90b0"><li>Finally, poor model performance could be caused not by your model but your <b>dataset construction</b>. Typical issues here include not having enough examples, dealing with noisy labels and imbalanced classes, splitting train and test set with different distributions.</li></ul><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-d426685f885d4e12873e6b0f0ca7bf26" data-id="d426685f885d4e12873e6b0f0ca7bf26"><span><div id="d426685f885d4e12873e6b0f0ca7bf26" class="notion-header-anchor"></div><a class="notion-hash-link" href="#d426685f885d4e12873e6b0f0ca7bf26" title="2 - Strategy to Debug Neural Networks"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">2 - Strategy to Debug Neural Networks</span></span></h4><div class="notion-text notion-block-1d5ff9ae0e8a4eb3a22226f312aa742f">The key idea of deep learning troubleshooting is: <em>Since it is hard to disambiguate errors, it’s best to start simple and gradually ramp up complexity.</em></div><div class="notion-text notion-block-7cecfe4ac84245f5b781983f1e5927cd">This lecture provides <b>a decision tree for debugging deep learning models and improving performance</b>. This guide assumes that you already have an initial test dataset, a single metric to improve, and target performance based on human-level performance, published results, previous baselines, etc.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-5ffa3a3f1fef494e92cb65365731d36b"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage4.png?table=block&amp;id=5ffa3a3f-1fef-494e-92cb-65365731d36b&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-110aa3e0e62d4462abcb63214a331990" data-id="110aa3e0e62d4462abcb63214a331990"><span><div id="110aa3e0e62d4462abcb63214a331990" class="notion-header-anchor"></div><a class="notion-hash-link" href="#110aa3e0e62d4462abcb63214a331990" title="3 - Start Simple"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">3 - Start Simple</span></span></h4><div class="notion-text notion-block-11ee9a31d8af40d1be25d9e383106893">The first step is the troubleshooting workflow is <b>starting simple</b>.</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-9b583af0299b42aea402ea3415241aa3" data-id="9b583af0299b42aea402ea3415241aa3"><span><div id="9b583af0299b42aea402ea3415241aa3" class="notion-header-anchor"></div><a class="notion-hash-link" href="#9b583af0299b42aea402ea3415241aa3" title="Choose A Simple Architecture"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Choose A Simple Architecture</b></span></span></h4><div class="notion-text notion-block-45296e7e335d4a0b85a997c8bdc9ad95">There are a few things to consider when you want to start simple. The first is how to <b>choose a simple architecture</b>. These are architectures that are easy to implement and are likely to get you part of the way towards solving your problem without introducing as many bugs.</div><div class="notion-text notion-block-3cb83298ecae4099921d54f8506ab574">Architecture selection is one of the many intimidating parts of getting into deep learning because there are tons of papers coming out all-the-time and claiming to be state-of-the-art on some problems. They get very complicated fast. In the limit, if you’re trying to get to maximal performance, then architecture selection is challenging. But when starting on a new problem, you can just solve a simple set of rules that will allow you to pick an architecture that enables you to do a decent job on the problem you’re working on.</div><ul class="notion-list notion-list-disc notion-block-2dd503b0148f4462bf442a6b41a115e8"><li>If your data looks like <b>images</b>, start with a LeNet-like architecture and consider using something like ResNet as your codebase gets more mature.</li></ul><ul class="notion-list notion-list-disc notion-block-421b58dba38c4a72abc10daddd457ef6"><li>If your data looks like <b>sequences</b>, start with an LSTM with one hidden layer and/or temporal/classical convolutions. Then, when your problem gets more mature, you can move to an Attention-based model or a WaveNet-like model.</li></ul><ul class="notion-list notion-list-disc notion-block-8c46d42c7c8441db9b04aff2690d57dd"><li>For <b>all other tasks</b>, start with a fully-connected neural network with one hidden layer and use more advanced networks later, depending on the problem.</li></ul><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-cf60285a7072470fb5afdfa826d1f815"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage7.png?table=block&amp;id=cf60285a-7072-470f-b5af-dfa826d1f815&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><div class="notion-text notion-block-63aab68c724a4e2195216e206d91f30f">In reality, many times, the input data contains multiple of those things above. So how to deal with <b>multiple input modalities</b> into a neural network? Here is the 3-step strategy that we recommend:</div><ul class="notion-list notion-list-disc notion-block-87c133235e3f4fb8b22c5ed8fd46f55e"><li>First, map each of these modalities into a lower-dimensional feature space. In the example above, the images are passed through a ConvNet, and the words are passed through an LSTM.</li></ul><ul class="notion-list notion-list-disc notion-block-332bf8c172414974891537dfb9ec5cad"><li>Then we flatten the outputs of those networks to get a single vector for each of the inputs that will go into the model. Then we concatenate those inputs.</li></ul><ul class="notion-list notion-list-disc notion-block-8591cffebaf44b819cd0a13fd4689170"><li>Finally, we pass them through some fully-connected layers to an output.</li></ul><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-a6572d92a0014d6c8f312742d62c83b5" data-id="a6572d92a0014d6c8f312742d62c83b5"><span><div id="a6572d92a0014d6c8f312742d62c83b5" class="notion-header-anchor"></div><a class="notion-hash-link" href="#a6572d92a0014d6c8f312742d62c83b5" title="Use Sensible Defaults"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Use Sensible Defaults</b></span></span></h4><div class="notion-text notion-block-758d28748f6c45b8aaa7542bd87017ea">After choosing a simple architecture, the next thing to do is to <b>select sensible hyper-parameter defaults</b> to start with. Here are the defaults that we recommend:</div><ul class="notion-list notion-list-disc notion-block-49e7e5b662da4616b687766a24bb7c34"><li><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://twitter.com/karpathy/status/801621764144971776?lang=en"><span class="notion-inline-underscore"><b>Adam optimizer with a “magic” learning rate value of 3e-4</b></span></a>.</li></ul><ul class="notion-list notion-list-disc notion-block-ffbb1023d94c4188a369d7400282ae82"><li><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it"><span class="notion-inline-underscore"><b>ReLU</b></span></a> activation for fully-connected and convolutional models and <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://stats.stackexchange.com/questions/330559/why-is-tanh-almost-always-better-than-sigmoid-as-an-activation-function"><span class="notion-inline-underscore"><b>Tanh</b></span></a> activation for LSTM models.</li></ul><ul class="notion-list notion-list-disc notion-block-70107c2cbcaa476fb19c3ff93fc8b0a5"><li><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://datascience.stackexchange.com/questions/13061/when-to-use-he-or-glorot-normal-initialization-over-uniform-init-and-what-are"><span class="notion-inline-underscore"><b>He initialization for ReLU activation function and Glorot initialization for Tanh activation function</b></span></a>.</li></ul><ul class="notion-list notion-list-disc notion-block-040da9772daa46dcb2bbef9e7a2e2d8e"><li>No regularization and data normalization.</li></ul><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-d4cbc4ee17a5480996173c619b183ab1" data-id="d4cbc4ee17a5480996173c619b183ab1"><span><div id="d4cbc4ee17a5480996173c619b183ab1" class="notion-header-anchor"></div><a class="notion-hash-link" href="#d4cbc4ee17a5480996173c619b183ab1" title="Normalize Inputs"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Normalize Inputs</b></span></span></h4><div class="notion-text notion-block-6ec5176f12ab4ba1b68de5ad92bfdc2e">The next step is to <b>normalize the input data</b>, subtracting the mean and dividing by the variance. Note that for images, it’s fine to scale values to [0, 1] or [-0.5, 0.5] (for example, by dividing by 255).</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-b0ed0084810e4102be245302081e77b0" data-id="b0ed0084810e4102be245302081e77b0"><span><div id="b0ed0084810e4102be245302081e77b0" class="notion-header-anchor"></div><a class="notion-hash-link" href="#b0ed0084810e4102be245302081e77b0" title="Simplify The Problem"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Simplify The Problem</b></span></span></h4><div class="notion-text notion-block-302aa177e89d445993c00a1b1885b175">The final thing you should do is consider <b>simplifying the problem</b> itself. If you have a complicated problem with massive data and tons of classes to deal with, then you should consider:</div><ul class="notion-list notion-list-disc notion-block-84d2098652104788ab78c12e3d0026d4"><li>Working with a small training set around 10,000 examples.</li></ul><ul class="notion-list notion-list-disc notion-block-ecb4f151df95446f91d950fc48616b45"><li>Using a fixed number of objects, classes, input size, etc.</li></ul><ul class="notion-list notion-list-disc notion-block-9b8d5c4547d44bd98828978b0bac97b6"><li>Creating a simpler synthetic training set like in research labs.</li></ul><div class="notion-text notion-block-7236441c8d2f4e39ae2ed5f011826f8a">This is important because (1) you will have reasonable confidence that your model should be able to solve, and (2) your iteration speed will increase.</div><div class="notion-text notion-block-aed72b915b2542a58dd3ef834bba4e3e">The diagram below neatly summarizes how to start simple:</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-8dd5db246ba74ec08b6edc300f218942"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage6.png?table=block&amp;id=8dd5db24-6ba7-4ec0-8b6e-dc300f218942&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-4fb20f9d6618489587a55c2680c65758" data-id="4fb20f9d6618489587a55c2680c65758"><span><div id="4fb20f9d6618489587a55c2680c65758" class="notion-header-anchor"></div><a class="notion-hash-link" href="#4fb20f9d6618489587a55c2680c65758" title="4 - Implement and Debug"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">4 - Implement and Debug</span></span></h4><div class="notion-text notion-block-6f8d56f1586d4493b87dc04356c2053f">To give you a preview, below are the five most common bugs in deep learning models that we recognize:</div><ul class="notion-list notion-list-disc notion-block-3cc9365f7801411b89e631077e15378c"><li><b>Incorrect shapes for the network tensors</b>: This bug is a common one and can fail silently. This happens many times because the automatic differentiation systems in the deep learning framework do silent broadcasting. Tensors become different shapes in the network and can cause a lot of problems.</li></ul><ul class="notion-list notion-list-disc notion-block-bb5726289074450a84e18ee7ac2620dd"><li><b>Pre-processing inputs incorrectly</b>: For example, you forget to normalize your inputs or apply too much input pre-processing (over-normalization and excessive data augmentation).</li></ul><ul class="notion-list notion-list-disc notion-block-c890aa4e4e8b4bd2b120cf6d20c095c1"><li><b>Incorrect input to the model’s loss function</b>: For example, you use softmax outputs to a loss that expects logits.</li></ul><ul class="notion-list notion-list-disc notion-block-bb2d48a055ee4019b28e2f979cb91f0a"><li><b>Forgot to set up train mode for the network correctly</b>: For example, toggling train/evaluation mode or controlling batch norm dependencies.</li></ul><ul class="notion-list notion-list-disc notion-block-9110d549d3d343d08c4098027a6e475d"><li><b>Numerical instability</b>: For example, you get `inf` or `NaN` as outputs. This bug often stems from using an exponent, a log, or a division operation somewhere in the code.</li></ul><div class="notion-text notion-block-edbf327e22f5436d8ffca50ef3ad90ae">Here are three pieces of general advice for implementing your model:</div><ul class="notion-list notion-list-disc notion-block-5909313a57f34b4da6694f7270d435f0"><li><b>Start with a lightweight implementation</b>. You want minimum possible new lines of code for the 1st version of your model. The rule of thumb is less than 200 lines. This doesn’t count tested infrastructure components or TensorFlow/PyTorch code.</li></ul><ul class="notion-list notion-list-disc notion-block-1b6441aa40f24ef490ed653430d34037"><li><b>Use off-the-shelf components</b> such as Keras if possible, since most of the stuff in Keras works well out-of-the-box. If you have to use TensorFlow, use the built-in functions, don’t do the math yourself. This would help you avoid a lot of numerical instability issues.</li></ul><ul class="notion-list notion-list-disc notion-block-348eecbd934e4f07b43f03327c303337"><li><b>Build complicated data pipelines later</b>. These are important for large-scale ML systems, but you should not start with them because data pipelines themselves can be a big source of bugs. Just start with a dataset that you can load into memory.</li></ul><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-e1cbd84b880a4937b473fe78e1b67eef"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage11.png?table=block&amp;id=e1cbd84b-880a-4937-b473-fe78e1b67eef&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-da1fc58418774a4e98be74f902e0af98" data-id="da1fc58418774a4e98be74f902e0af98"><span><div id="da1fc58418774a4e98be74f902e0af98" class="notion-header-anchor"></div><a class="notion-hash-link" href="#da1fc58418774a4e98be74f902e0af98" title="Get Your Model To Run"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Get Your Model To Run</b></span></span></h4><div class="notion-text notion-block-70e3bcdf56514d89b493bebea3696f28">The first step of implementing bug-free deep learning models is <b>getting your model to run at all</b>. There are a few things that can prevent this from happening:</div><ul class="notion-list notion-list-disc notion-block-d8fc3fb9f4c94cef9a1be86d772ad799"><li><b>Shape mismatch/casting issue</b>: To address this type of problem, you should step through your model creation and inference step-by-step in a debugger, checking for correct shapes and data types of your tensors.</li></ul><ul class="notion-list notion-list-disc notion-block-acbef404a65d404e8f36e5cb65240dba"><li><b>Out-of-memory issues</b>: This can be very difficult to debug. You can scale back your memory-intensive operations one-by-one. For example, if you create large matrices anywhere in your code, you can reduce the size of their dimensions or cut your batch size in half.</li></ul><ul class="notion-list notion-list-disc notion-block-574e5027b26e4ea089dd05d62f717ebd"><li><b>Other issues</b>: You can simply Google it. Stack Overflow would be great most of the time.</li></ul><div class="notion-text notion-block-70dce6982c1b44c6a306ef90f7442cbd">Let’s zoom in on the process of stepping through model creation in a debugger and talk about <b>debuggers for deep learning code</b>:</div><ul class="notion-list notion-list-disc notion-block-cd193184aa184d97b4726c7d0d49cf22"><li>In PyTorch, you can use <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://pypi.org/project/ipdb/"><span class="notion-inline-underscore"><b>ipdb</b></span></a> — which exports functions to access the interactive <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://ipython.org/"><span class="notion-inline-underscore"><b>IPython</b></span></a> debugger.</li></ul><ul class="notion-list notion-list-disc notion-block-bf1b8f19b9bb47f5be1a29276eb0b01d"><li>In TensorFlow, it’s trickier. TensorFlow separates the process of creating the graph and executing operations in the graph. There are three options you can try: (1) step through the graph creation itself and inspect each tensor layer, (2) step into the training loop and evaluate the tensor layers, or (3) use <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://mullikine.github.io/posts/tensorflow-debugger-tfdb-and-emacs/"><span class="notion-inline-underscore"><b>TensorFlow Debugger</b></span></a> (tfdb), which does option 1 and 2 automatically.</li></ul><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-5522019ef49d4e8da27d138418290db6"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage14.png?table=block&amp;id=5522019e-f49d-4e8d-a27d-138418290db6&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-b9c00fb285474f5b8acb849c4d0e4c4e" data-id="b9c00fb285474f5b8acb849c4d0e4c4e"><span><div id="b9c00fb285474f5b8acb849c4d0e4c4e" class="notion-header-anchor"></div><a class="notion-hash-link" href="#b9c00fb285474f5b8acb849c4d0e4c4e" title="Overfit A Single Batch"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Overfit A Single Batch</b></span></span></h4><div class="notion-text notion-block-a287c35de430449dbcedc4fc7573d292">After getting your model to run, the next thing you need to do is to <b>overfit a single batch of data</b>. This is a heuristic that can catch an absurd number of bugs. This really means that you want to drive your training error arbitrarily close to 0.</div><div class="notion-text notion-block-a1f53d1398224344a2e79e2dfda8d0bd">There are a few things that can happen when you try to overfit a single batch and it fails:</div><ul class="notion-list notion-list-disc notion-block-fc218291c46048a7a19b239d645f1255"><li><b>Error goes up</b>: Commonly, this is due to a flip sign somewhere in the loss function/gradient.</li></ul><ul class="notion-list notion-list-disc notion-block-ab53b9b0fcc2434bbf7067b11388f861"><li><b>Error explodes</b>: This is usually a numerical issue but can also be caused by a high learning rate.</li></ul><ul class="notion-list notion-list-disc notion-block-4591992d87f849c8bb947ce12c03bff4"><li><b>Error oscillates</b>: You can lower the learning rate and inspect the data for shuffled labels or incorrect data augmentation.</li></ul><ul class="notion-list notion-list-disc notion-block-4dcc47aeec8e4e31aa2741ff5a74cdb9"><li><b>Error plateaus</b>: You can increase the learning rate and get rid of regulation. Then you can inspect the loss function and the data pipeline for correctness.</li></ul><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-970fd873725a40e88cc590d8a9833f0d"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage10.png?table=block&amp;id=970fd873-725a-40e8-8cc5-90d8a9833f0d&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-2b817cb3eaa34abb8f33db65a6119811" data-id="2b817cb3eaa34abb8f33db65a6119811"><span><div id="2b817cb3eaa34abb8f33db65a6119811" class="notion-header-anchor"></div><a class="notion-hash-link" href="#2b817cb3eaa34abb8f33db65a6119811" title="Compare To A Known Result"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Compare To A Known Result</b></span></span></h4><div class="notion-text notion-block-9992cd8b87aa427cae64fd5c260e42da">Once your model overfits in a single batch, there can still be some other issues that cause bugs. The last step here is to <b>compare your results to a known result</b>. So what sort of known results are useful?</div><ul class="notion-list notion-list-disc notion-block-604338adc8ed4f2da166f6c2dc937f6b"><li>The most useful results come from <b>an official model implementation evaluated on a similar dataset to yours</b>. You can step through the code in both models line-by-line and ensure your model has the same output. You want to ensure that your model performance is up to par with expectations.</li></ul><ul class="notion-list notion-list-disc notion-block-bcfa88141268417e931c7d87e914ae27"><li>If you can’t find an official implementation on a similar dataset, you can compare your approach to results from <b>an official model implementation evaluated on a benchmark dataset</b>. You most definitely want to walk through the code line-by-line and ensure you have the same output.</li></ul><ul class="notion-list notion-list-disc notion-block-b73981d9812c42a18f12243428eda8ed"><li>If there is no official implementation of your approach, you can compare it to results from <b>an unofficial model implementation</b>. You can review the code the same as before but with lower confidence (because almost all the unofficial implementations on GitHub have bugs).</li></ul><ul class="notion-list notion-list-disc notion-block-27c595258a8c4006890e3c8b140c57ed"><li>Then, you can compare to results from <b>a paper with no code</b> (to ensure that your performance is up to par with expectations), results from <b>your model on a benchmark dataset</b> (to make sure your model performs well in a simpler setting), and results from <b>a similar model on a similar dataset</b> (to help you get a general sense of what kind of performance can be expected).</li></ul><ul class="notion-list notion-list-disc notion-block-ac9045a749a74ccd91dc972f46ee1909"><li>An under-rated source of results comes from <b>simple baselines</b> (for example, the average of outputs or linear regression), which can help make sure that your model is learning anything at all.</li></ul><div class="notion-text notion-block-fc59deaea3494e629b42986b20f69645">The diagram below neatly summarizes how to implement and debug deep neural networks:</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-bb1fd6375e7e491b9a57ea1c4b6115b9"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage8.png?table=block&amp;id=bb1fd637-5e7e-491b-9a57-ea1c4b6115b9&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-fe6778d1324a4633a8b2cb80b9a2345e" data-id="fe6778d1324a4633a8b2cb80b9a2345e"><span><div id="fe6778d1324a4633a8b2cb80b9a2345e" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fe6778d1324a4633a8b2cb80b9a2345e" title="5 - Evaluate"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">5 - Evaluate</span></span></h4><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-032c21fedabc40f4be739e98b242cf8a" data-id="032c21fedabc40f4be739e98b242cf8a"><span><div id="032c21fedabc40f4be739e98b242cf8a" class="notion-header-anchor"></div><a class="notion-hash-link" href="#032c21fedabc40f4be739e98b242cf8a" title="Bias-Variance Decomposition"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Bias-Variance Decomposition</b></span></span></h4><div class="notion-text notion-block-cf84dcc5c4f9463c9d1a56843b773bf5">To evaluate models and prioritize the next steps in model development, we will apply the bias-variance decomposition. The <a target="_blank" rel="noopener noreferrer" class="notion-link" href="http://scott.fortmann-roe.com/docs/BiasVariance.html"><span class="notion-inline-underscore"><b>bias-variance decomposition</b></span></a> is the fundamental model fitting tradeoff. In our application, let’s talk more specifically about the formula for bias-variance tradeoff with respect to the <b>test error;</b> this will help us apply the concept more directly to our model’s performance. There are four terms in the formula for test error:</div><div class="notion-text notion-block-8ae2f905a64944e694d2cb3cfae7007f"><em>Test error = irreducible error + bias + variance + validation overfitting</em></div><ol start="1" class="notion-list notion-list-numbered notion-block-9355b3772dae468398f669a220a9aece"><li><b>Irreducible error</b> is the baseline error you don’t expect your model to do better. It can be estimated through strong baselines, like human performance.</li></ol><ol start="2" class="notion-list notion-list-numbered notion-block-c779947ae76c4e2282c29d032e9c4797"><li><b>Avoidable bias</b>, a measure of underfitting, is the difference between our train error and irreducible error.</li></ol><ol start="3" class="notion-list notion-list-numbered notion-block-701b3e42ad514bb9bfd1f51712619882"><li><b>Variance</b>, a measure of overfitting, is the difference between validation error and training error.</li></ol><ol start="4" class="notion-list notion-list-numbered notion-block-cdc4a618a3284e6fb593fd8b6de86c73"><li><b>Validation set overfitting</b> is the difference between test error and validation error.</li></ol><div class="notion-text notion-block-b841b560bb4144abb3c9bca8d3b441d4">Consider the chart of learning curves and errors below. Using the test error formula for bias and variance, we can calculate each component of test error and make decisions based on the value. For example, our avoidable bias is rather low (only 2 points), while the variance is much higher (5 points). With this knowledge, we should prioritize methods of preventing overfitting, like regularization.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-65c45cac8c0d4c4eae064b7edf3a9c3d"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage12.png?table=block&amp;id=65c45cac-8c0d-4c4e-ae06-4b7edf3a9c3d&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-dabfba894616412d8f8e7344b23469e1" data-id="dabfba894616412d8f8e7344b23469e1"><span><div id="dabfba894616412d8f8e7344b23469e1" class="notion-header-anchor"></div><a class="notion-hash-link" href="#dabfba894616412d8f8e7344b23469e1" title="Distribution Shift"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Distribution Shift</b></span></span></h4><div class="notion-text notion-block-13c8d82c18b74eca98bec1412057e965">Clearly, the application of the bias-variance decomposition to the test error has already helped prioritize our next steps for model development. However, until now, we’ve assumed that the samples (training, validation, testing) all come from the same distribution. What if this isn’t the case? In practical ML situations, this <b>distribution shift</b> often cars. In building self-driving cars, a frequent occurrence might be training with samples from one distribution (e.g., daytime driving video) but testing or inferring on samples from a totally different distribution (e.g., night time driving).</div><div class="notion-text notion-block-ef425645faa74249aa5b4cb2ac36f30a">A simple way of handling this wrinkle in our assumption is to create two validation sets: one from the training distribution and one from the test distribution. This can be helpful even with a very small testing set. If we apply this, we can actually estimate our distribution shift, which is the difference between testing validation error and testing error. This is really useful for practical applications of ML! With this new term, let’s update our test error formula of bias and variance:</div><div class="notion-text notion-block-ed5d263515d1426cb50cf50bc84ecfe8"><em>Test error = irreducible error + bias + variance + distribution shift + validation overfitting</em></div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-7b62a9d43de74ba394ee9693447f6de3" data-id="7b62a9d43de74ba394ee9693447f6de3"><span><div id="7b62a9d43de74ba394ee9693447f6de3" class="notion-header-anchor"></div><a class="notion-hash-link" href="#7b62a9d43de74ba394ee9693447f6de3" title="6 - Improve Model and Data"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">6 - Improve Model and Data</span></span></h4><div class="notion-text notion-block-d29d70e1a6cf4fb799d2ee3823dc28c6">Using the updated formula from the last section, we’ll be able to decide on and prioritize the right next steps for each iteration of a model. In particular, we’ll follow a specific process (shown below).</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fae2fdbce79a421fbf24a9395b131b86"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage1.png?table=block&amp;id=fae2fdbc-e79a-421f-bf24-a9395b131b86&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-b47b8e05a109475c99b90ed9596ec6d2" data-id="b47b8e05a109475c99b90ed9596ec6d2"><span><div id="b47b8e05a109475c99b90ed9596ec6d2" class="notion-header-anchor"></div><a class="notion-hash-link" href="#b47b8e05a109475c99b90ed9596ec6d2" title="Step 1: Address Underfitting"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Step 1: Address Underfitting</b></span></span></h4><div class="notion-text notion-block-95b3bf1db3d64aec955500674082e53d">We’ll start by addressing underfitting (i.e., reducing bias). The first thing to try in this case is to make your model bigger (e.g., add layers, more units per layer). Next, consider regularization, which can prevent a tight fit to your data. Other options are error analysis, choosing a different model architecture (e.g., something more state of the art), tuning hyperparameters, or adding features. Some notes:</div><ul class="notion-list notion-list-disc notion-block-9cc7d12e93554335b265f813fae9c5f7"><li>Choosing different architectures, especially a SOTA one, can be very helpful but is also risky. Bugs are easily introduced in the implementation process.</li></ul><ul class="notion-list notion-list-disc notion-block-a570ff5ed4ce4ef29fa16924fdd9cd1f"><li>Adding features is uncommon in the deep learning paradigm (vs. traditional machine learning). We usually want the network to learn features of its own accord. If all else fails, it can be beneficial in a practical setting.</li></ul><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-b643ac16059145b9ad377b6b60b1a01e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage13.png?table=block&amp;id=b643ac16-0591-45b9-ad37-7b6b60b1a01e&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-93ef9497a2e7452f985a563a021eb47c" data-id="93ef9497a2e7452f985a563a021eb47c"><span><div id="93ef9497a2e7452f985a563a021eb47c" class="notion-header-anchor"></div><a class="notion-hash-link" href="#93ef9497a2e7452f985a563a021eb47c" title="Step 2: Address Overfitting"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Step 2: Address Overfitting</b></span></span></h4><div class="notion-text notion-block-50fc1ef512424f18ae3ca97152737845">After addressing underfitting, move on to solving overfitting. Similarly, there’s a recommended series of methods to try in order. Starting with collecting training data (if possible) is the soundest way to address overfitting, though it can be challenging in certain applications. Next, tactical improvements like normalization, data augmentation, and regularization can help. Following these steps, traditional defaults like tuning hyperparameters, choosing a different architecture, or error analysis are useful. Finally, if overfitting is rather intractable, there’s a series of less recommended steps, such as early stopping, removing features, and reducing model size. Early stopping is a personal choice; the fast.ai community is a strong proponent.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-b83b67bced104eaaac5f686ac36d49ce"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage15.png?table=block&amp;id=b83b67bc-ed10-4eaa-ac5f-686ac36d49ce&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-6b4b39135fd448cd964da18720f4d297" data-id="6b4b39135fd448cd964da18720f4d297"><span><div id="6b4b39135fd448cd964da18720f4d297" class="notion-header-anchor"></div><a class="notion-hash-link" href="#6b4b39135fd448cd964da18720f4d297" title="Step 3: Address Distribution Shift"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Step 3: Address Distribution Shift</b></span></span></h4><div class="notion-text notion-block-f1f202218f794737a527ebd56b0fa8d3">After addressing underfitting and overfitting, If there’s a difference between the error on our training validation set vs. our test validation set, we need to address the error caused by the distribution shift. This is a harder problem to solve, so there’s less in our toolkit to apply.</div><div class="notion-text notion-block-0610ff1cc1194295b36a7e8117ee38c5">Start by looking manually at the errors in the test-validation set. Compare the potential logic behind these errors to the performance in the train-validation set, and use the errors to guide further data collection. Essentially, reason about why your model may be suffering from distribution shift error. This is the most principled way to deal with distribution shift, though it’s the most challenging way practically. If collecting more data to address these errors isn’t possible, try synthesizing data. Additionally, you can try <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://ece.engin.umich.edu/wp-content/uploads/2019/09/4142.pdf"><span class="notion-inline-underscore"><b>domain adaptation</b></span></a>.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1d13f597141e4426ad02aa9b69fd68e6"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage9.png?table=block&amp;id=1d13f597-141e-4426-ad02-aa9b69fd68e6&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-25677321009e4a9aacb8e79dc2c5b45d" data-id="25677321009e4a9aacb8e79dc2c5b45d"><span><div id="25677321009e4a9aacb8e79dc2c5b45d" class="notion-header-anchor"></div><a class="notion-hash-link" href="#25677321009e4a9aacb8e79dc2c5b45d" title="ERROR ANALYSIS"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>ERROR ANALYSIS</b></span></span></h4><div class="notion-text notion-block-03df163456a54a47864691f3d6032eb0">Manually evaluating errors to understand model performance is generally a high-yield way of figuring out how to improve the model. Systematically performing this <b>error analysis</b> process and decomposing the error from different error types can help prioritize model improvements. For example, in a self-driving car use case with error types like hard-to-see pedestrians, reflections, and nighttime scenes, decomposing the error contribution of each and where it occurs (train-val vs. test-val) can give rise to a clear set of prioritized action items. See the table for an example of how this error analysis can be effectively structured.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-6308220800d341ddb0baadfd3794c9d6"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage5.png?table=block&amp;id=63082208-00d3-41dd-b0ba-adfd3794c9d6&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-e8c55e41b1c24a2d96ed4ead437558cf" data-id="e8c55e41b1c24a2d96ed4ead437558cf"><span><div id="e8c55e41b1c24a2d96ed4ead437558cf" class="notion-header-anchor"></div><a class="notion-hash-link" href="#e8c55e41b1c24a2d96ed4ead437558cf" title="DOMAIN ADAPTATION"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>DOMAIN ADAPTATION</b></span></span></h4><div class="notion-text notion-block-a6b4ab4d86bc49a383d32bdd0b348cad">Domain adaptation is a class of techniques that train on a “source” distribution and generalize to another “target” using only unlabeled data or limited labeled data. You should use domain adaptation when access to labeled data from the test distribution is limited, but access to relatively similar data is plentiful.</div><div class="notion-text notion-block-80c75dffbbbc4a2f8bbab5118c2f91ad">There are a few different types of domain adaptation:</div><ol start="1" class="notion-list notion-list-numbered notion-block-481b613593134a5690e0092d61f794cb"><li><b>Supervised domain adaptation</b>: In this case, we have limited data from the target domain to adapt to. Some example applications of the concept include fine-tuning a pre-trained model or adding target data to a training set.</li></ol><ol start="2" class="notion-list notion-list-numbered notion-block-aa718d5aab1b4d5380aa8874f10bf0f5"><li><b>Unsupervised domain adaptation</b>: In this case, we have lots of unlabeled data from the target domain. Some techniques you might see are CORAL, domain confusion, and CycleGAN.</li></ol><div class="notion-text notion-block-f418364ef36e46d59bb020fd02c886bf">Practically speaking, supervised domain adaptation can work really well! Unsupervised domain adaptation has a little bit further to go.</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-848bb57ef69c471686cd79d83b465110" data-id="848bb57ef69c471686cd79d83b465110"><span><div id="848bb57ef69c471686cd79d83b465110" class="notion-header-anchor"></div><a class="notion-hash-link" href="#848bb57ef69c471686cd79d83b465110" title="Step 4: Rebalance datasets"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Step 4: Rebalance datasets</b></span></span></h4><div class="notion-text notion-block-b8cc18337e9344a189f16e56ffb21657">If the test-validation set performance starts to look considerably better than the test performance, you may have overfit the validation set. This commonly occurs with small validation sets or lots of hyperparameter training. If this occurs, resample the validation set from the test distribution and get a fresh estimate of the performance.</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-0e5f89060d7b4084b2b3fbc908e98b59" data-id="0e5f89060d7b4084b2b3fbc908e98b59"><span><div id="0e5f89060d7b4084b2b3fbc908e98b59" class="notion-header-anchor"></div><a class="notion-hash-link" href="#0e5f89060d7b4084b2b3fbc908e98b59" title="7 - Tune Hyperparameters"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">7 - Tune Hyperparameters</span></span></h4><div class="notion-text notion-block-ac79660c5c724ebfa16771a3891c3f2b">One of the core challenges in hyperparameter optimization is very basic: <b>which hyperparameters should you tune?</b> As we consider this fundamental question, let’s keep the following in mind:</div><ul class="notion-list notion-list-disc notion-block-c721d6c586e745569bc7de85e0bcc330"><li>Models are more sensitive to some hyperparameters than others. This means we should focus our efforts on the more impactful hyperparameters.</li></ul><ul class="notion-list notion-list-disc notion-block-2c76c89ecb56438d98596127869bd459"><li>However, which hyperparameters are most important depends heavily on our choice of model.</li></ul><ul class="notion-list notion-list-disc notion-block-c65863821b0546e39b3a0d1fb17b4b5e"><li>Certain rules of thumbs can help guide our initial thinking.</li></ul><ul class="notion-list notion-list-disc notion-block-b23c9a46a04041408acb2dc3add0b0dc"><li>Sensitivity is always relative to default values; if you use good defaults, you might start in a good place!</li></ul><div class="notion-text notion-block-9cd74b51a6f344ee8cf1b8758a9146ce">See the following table for a ranked list of hyperparameters and their impact on the model:</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-a2c45c2bc9994bd193ba1a7cbfee5b36"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column"><img src="https://www.notion.so/image/https%3A%2F%2Ffullstackdeeplearning.com%2Fspring2021%2Flecture-7-notes-media%2Fimage2.png?table=block&amp;id=a2c45c2b-c999-4bd1-93ba-1a7cbfee5b36&amp;cache=v2" loading="lazy" alt="notion image" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-bc5e35e3be9e425fb1a4742286d7924a" data-id="bc5e35e3be9e425fb1a4742286d7924a"><span><div id="bc5e35e3be9e425fb1a4742286d7924a" class="notion-header-anchor"></div><a class="notion-hash-link" href="#bc5e35e3be9e425fb1a4742286d7924a" title="Techniques for Tuning Hyperparameter Optimization"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>Techniques for Tuning Hyperparameter Optimization</b></span></span></h4><div class="notion-text notion-block-6d52c5d62aaf4d898ad0ceba80efd903">Now that we know which hyperparameters make the most sense to tune (using rules of thumb), let’s consider the various methods of actually tuning them:</div><ol start="1" class="notion-list notion-list-numbered notion-block-ba78d23c4bf6458a937986d9af3c268a"><li><b>Manual Hyperparameter Optimization</b>. Colloquially referred to as Graduate Student Descent, this method works by taking a manual, detailed look at your algorithm, building intuition, and considering which hyperparameters would make the most difference. After figuring out these parameters, you train, evaluate, and guess a better hyperparameter value using your intuition for the algorithm and intelligence. While it may seem archaic, this method combines well with other methods (e.g., setting a range of values for hyperparameters) and has the main benefit of reducing computation time and cost if used skillfully. It can be time-consuming and challenging, but it can be a good starting point.</li></ol><ol start="2" class="notion-list notion-list-numbered notion-block-220ef235283b4e8bad6ca9467c7c91cd"><li><b>Grid Search</b>. Imagine each of your parameters plotted against each other on a grid, from which you uniformly sample values to test. For each point, you run a training run and evaluate performance. The advantages are that it’s very simple and can often produce good results. However, it’s quite inefficient, as you must run every combination of hyperparameters. It also often requires prior knowledge about the hyperparameters since we must manually set the range of values.</li></ol><ol start="3" class="notion-list notion-list-numbered notion-block-df9e48a97dee401296e02534c8518f39"><li><b>Random Search</b>: This method is recommended over grid search. Rather than sampling from the grid of values for the hyperparameter evenly, we’ll choose n points sampled randomly across the grid. Empirically, this method produces better results than grid search. However, the results can be somewhat uninterpretable, with unexpected values in certain hyperparameters returned.</li></ol><ol start="4" class="notion-list notion-list-numbered notion-block-2e9fb20f03d54427a28c8f02427ca02e"><li><b>Coarse-to-fine Search</b>: Rather than running entirely random runs, we can gradually narrow in on the best hyperparameters through this method. Initially, start by defining a very large range to run a randomized search on. Within the pool of results, you can find N best results and hone in on the hyperparameter values used to generate those samples. As you iteratively perform this method, you can get excellent performance. This doesn’t remove the manual component, as you have to select which range to continuously narrow your search to, but it’s perhaps the most popular method available.</li></ol><ol start="5" class="notion-list notion-list-numbered notion-block-86558bbf283d4126a2fbd1884a8a938e"><li><b>Bayesian Hyperparameter Optimization</b>: This is a reasonably sophisticated method, which you can read more about <a target="_blank" rel="noopener noreferrer" class="notion-link" href="http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec21.pdf"><span class="notion-inline-underscore"><b>here</b></span></a> and <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"><span class="notion-inline-underscore"><b>here</b></span></a>. At a high level, start with a prior estimate of parameter distributions. Subsequently, maintain a probabilistic model of the relationship between hyperparameter values and model performance. As you maintain this model, you toggle between training with hyperparameter values that maximize the expected improvement (per the model) and use training results to update the initial probabilistic model and its expectations. This is a great, hands-off, efficient method to choose hyperparameters. However, these techniques can be quite challenging to implement from scratch. As libraries and infrastructure mature, the integration of these methods into training will become easier.</li></ol><div class="notion-text notion-block-a2c44c7f975a439ca47b841e3921d1a7">In summary, you should probably start with coarse-to-fine random searches and move to Bayesian methods as your codebase matures and you’re more certain of your model.</div><h4 class="notion-h notion-h3 notion-h-indent-0 notion-block-2956286aa232482099c8c9fd4c307182" data-id="2956286aa232482099c8c9fd4c307182"><span><div id="2956286aa232482099c8c9fd4c307182" class="notion-header-anchor"></div><a class="notion-hash-link" href="#2956286aa232482099c8c9fd4c307182" title="8 - Conclusion"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">8 - Conclusion</span></span></h4><div class="notion-text notion-block-639d9f200fab4e75acfeaf995d9b9434">To wrap up this lecture, deep learning troubleshooting and debugging is really hard. It’s difficult to tell if you have a bug because there are many possible sources for the same degradation in performance. Furthermore, the results can be sensitive to small changes in hyper-parameters and dataset makeup.</div><div class="notion-text notion-block-e23a34ecd5054cdb86fe1e4b82d32072">To train bug-free deep learning models, we need to treat building them as an iterative process. If you skipped to the end, the following steps can make this process easier and catch errors as early as possible:</div><ul class="notion-list notion-list-disc notion-block-45c565fa95d14dbaabb59a80d1d2a493"><li><b>Start Simple</b>: Choose the simplest model and data possible.</li></ul><ul class="notion-list notion-list-disc notion-block-ae01af56fa534ce5965cbc1210a645e9"><li><b>Implement and Debug</b>: Once the model runs, overfit a single batch and reproduce a known result.</li></ul><ul class="notion-list notion-list-disc notion-block-84039c01ee094c49a9dc5f425e9b97fd"><li><b>Evaluate</b>: Apply the bias-variance decomposition to decide what to do next.</li></ul><ul class="notion-list notion-list-disc notion-block-91635917fdca406dbf3b382c1765e3f8"><li><b>Tune Hyper-parameters</b>: Use coarse-to-fine random searches to tune the model’s hyper-parameters.</li></ul><ul class="notion-list notion-list-disc notion-block-ec70b5e2baa844329468a92a469a6843"><li><b>Improve Model and Data</b>: Make your model bigger if your model under-fits and add more data and/or regularization if your model over-fits.</li></ul><div class="notion-text notion-block-ab654ab42f3a4d3a923e68c060cf31b8">Here are additional resources that you can go to learn more:</div><ul class="notion-list notion-list-disc notion-block-79247fa94d534a8cab2840ac3d768e39"><li>Andrew Ng’s “<a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://www.deeplearning.ai/machine-learning-yearning/"><span class="notion-inline-underscore"><b>Machine Learning Yearning</b></span></a>” book.</li></ul><ul class="notion-list notion-list-disc notion-block-e9cbabbbd57142eba62d64c952348cde"><li>This <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://twitter.com/karpathy/status/1013244313327681536"><span class="notion-inline-underscore"><b>Twitter thread</b></span></a> from Andrej Karpathy.</li></ul><ul class="notion-list notion-list-disc notion-block-eed49f335d7b4f6fbfcd6456c8c73133"><li>BYU’s “<a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neural-networks/"><span class="notion-inline-underscore"><b>Practical Advice for Building Deep Neural Networks</b></span></a>” blog post.</li></ul></article><aside class="notion-aside"><div class="notion-aside-table-of-contents"><div class="notion-aside-table-of-contents-header">Table of Contents</div><nav class="notion-table-of-contents notion-gray"><a href="#68839e035ecf47ee9ed4cceb22350031" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">1 - Why Is Deep Learning Troubleshooting Hard?</span></a><a href="#d426685f885d4e12873e6b0f0ca7bf26" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">2 - Strategy to Debug Neural Networks</span></a><a href="#110aa3e0e62d4462abcb63214a331990" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">3 - Start Simple</span></a><a href="#9b583af0299b42aea402ea3415241aa3" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Choose A Simple Architecture</span></a><a href="#a6572d92a0014d6c8f312742d62c83b5" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Use Sensible Defaults</span></a><a href="#d4cbc4ee17a5480996173c619b183ab1" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Normalize Inputs</span></a><a href="#b0ed0084810e4102be245302081e77b0" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Simplify The Problem</span></a><a href="#4fb20f9d6618489587a55c2680c65758" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">4 - Implement and Debug</span></a><a href="#da1fc58418774a4e98be74f902e0af98" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Get Your Model To Run</span></a><a href="#b9c00fb285474f5b8acb849c4d0e4c4e" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Overfit A Single Batch</span></a><a href="#2b817cb3eaa34abb8f33db65a6119811" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Compare To A Known Result</span></a><a href="#fe6778d1324a4633a8b2cb80b9a2345e" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">5 - Evaluate</span></a><a href="#032c21fedabc40f4be739e98b242cf8a" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Bias-Variance Decomposition</span></a><a href="#dabfba894616412d8f8e7344b23469e1" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Distribution Shift</span></a><a href="#7b62a9d43de74ba394ee9693447f6de3" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">6 - Improve Model and Data</span></a><a href="#b47b8e05a109475c99b90ed9596ec6d2" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Step 1: Address Underfitting</span></a><a href="#93ef9497a2e7452f985a563a021eb47c" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Step 2: Address Overfitting</span></a><a href="#6b4b39135fd448cd964da18720f4d297" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Step 3: Address Distribution Shift</span></a><a href="#25677321009e4a9aacb8e79dc2c5b45d" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">ERROR ANALYSIS</span></a><a href="#e8c55e41b1c24a2d96ed4ead437558cf" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">DOMAIN ADAPTATION</span></a><a href="#848bb57ef69c471686cd79d83b465110" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Step 4: Rebalance datasets</span></a><a href="#0e5f89060d7b4084b2b3fbc908e98b59" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">7 - Tune Hyperparameters</span></a><a href="#bc5e35e3be9e425fb1a4742286d7924a" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">Techniques for Tuning Hyperparameter Optimization</span></a><a href="#2956286aa232482099c8c9fd4c307182" class="notion-table-of-contents-item notion-table-of-contents-item-indent-level-0"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">8 - Conclusion</span></a></nav></div><div class="PageSocial_pageSocial__2WqHl"><a class="PageSocial_action__2zgVt PageSocial_twitter__-BgFt" href="https://yihui-he.github.io" title="personal website" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#000000" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path><polyline points="9 22 9 12 15 12 15 22"></polyline></svg></div></a><a class="PageSocial_action__2zgVt PageSocial_twitter__-BgFt" href="https://twitter.com/he_yi_hui" title="Twitter @he_yi_hui" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"></path></svg></div></a><a class="PageSocial_action__2zgVt PageSocial_github__slQ0z" href="https://github.com/yihui-he" title="GitHub @yihui-he" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></div></a><a class="PageSocial_action__2zgVt PageSocial_linkedin__nElHT" href="https://www.linkedin.com/in/yihui-he-a4257aab" title="LinkedIn Yihui He" target="_blank" rel="noopener noreferrer"><div class="PageSocial_actionBg__3CigO"><div class="PageSocial_actionBgPane__gbBkL"></div></div><div class="PageSocial_actionBg__3CigO"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"></path></svg></div></a></div></aside></div></main><footer class="styles_footer__1r_c6"><div class="styles_copyright__3kWHj">Copyright 2022 <!-- -->Yihui He</div><div class="styles_social__235gY"><a class="styles_twitter__WwfaA" href="https://yihui-he.github.io" title="Twitter @he_yi_hui" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"></path></svg></a><a class="styles_twitter__WwfaA" href="https://twitter.com/he_yi_hui" title="Twitter @he_yi_hui" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a class="styles_github__32xIr" href="https://github.com/yihui-he" title="GitHub @yihui-he" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a class="styles_linkedin__1XGvB" href="https://www.linkedin.com/in/yihui-he-a4257aab" title="LinkedIn Yihui He" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></div></footer></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"site":{"domain":"yihui-he.github.io","name":"Yihui He","rootNotionPageId":"bd32b787e47149f38941174a9c6846b6","rootNotionSpaceId":null,"description":"Yihui He, AI research scientist / full stack engineer"},"recordMap":{"block":{"94cea945-881b-4d6b-be5c-505834b715db":{"role":"reader","value":{"id":"94cea945-881b-4d6b-be5c-505834b715db","version":156,"type":"page","properties":{"title":[["Troubleshooting Deep Neural Networks",[["b"]]]]},"content":["c24004db-f73b-44e5-b8fa-44ebcf22447a","6723210b-5c98-40ad-b479-2473a93ea4be","68839e03-5ecf-47ee-9ed4-cceb22350031","6c1553da-9d24-4e84-b386-06f7e53c4c19","39a7abde-b07d-4436-8dae-4f48261a582a","54e72d65-b5db-49d3-bd40-26e623712f6d","7b51d6b5-38b5-4fe4-99d6-5ee9bcddb8ca","2288e49d-eac9-4238-a3ed-953c8ed31067","15662054-e89e-468f-927f-2e21471fb714","dd3420dd-f5ca-47c2-b331-dbd41e5a90b0","d426685f-885d-4e12-873e-6b0f0ca7bf26","1d5ff9ae-0e8a-4eb3-a222-26f312aa742f","7cecfe4a-c842-45f5-b781-983f1e5927cd","5ffa3a3f-1fef-494e-92cb-65365731d36b","110aa3e0-e62d-4462-abcb-63214a331990","11ee9a31-d8af-40d1-be25-d9e383106893","9b583af0-299b-42ae-a402-ea3415241aa3","45296e7e-335d-4a0b-85a9-97c8bdc9ad95","3cb83298-ecae-4099-921d-54f8506ab574","2dd503b0-148f-4462-bf44-2a6b41a115e8","421b58db-a38c-4a72-abc1-0daddd457ef6","8c46d42c-7c84-41db-9b04-aff2690d57dd","cf60285a-7072-470f-b5af-dfa826d1f815","63aab68c-724a-4e21-9521-6e206d91f30f","87c13323-5e3f-4fb8-b22c-5ed8fd46f55e","332bf8c1-7241-4974-8915-37dfb9ec5cad","8591cffe-baf4-4b81-9cd0-a13fd4689170","a6572d92-a001-4d6c-8f31-2742d62c83b5","758d2874-8f6c-45b8-aaa7-542bd87017ea","49e7e5b6-62da-4616-b687-766a24bb7c34","ffbb1023-d94c-4188-a369-d7400282ae82","70107c2c-bcaa-476f-b19c-3ff93fc8b0a5","040da977-2daa-46dc-b2bb-ef9e7a2e2d8e","d4cbc4ee-17a5-4809-9617-3c619b183ab1","6ec5176f-12ab-4ba1-b68d-e5ad92bfdc2e","b0ed0084-810e-4102-be24-5302081e77b0","302aa177-e89d-4459-93c0-0a1b1885b175","84d20986-5210-4788-ab78-c12e3d0026d4","ecb4f151-df95-446f-91d9-50fc48616b45","9b8d5c45-47d4-4bd9-8828-978b0bac97b6","7236441c-8d2f-4e39-ae2e-d5f011826f8a","aed72b91-5b25-42a5-8dd3-ef834bba4e3e","8dd5db24-6ba7-4ec0-8b6e-dc300f218942","4fb20f9d-6618-4895-87a5-5c2680c65758","6f8d56f1-586d-4493-b87d-c04356c2053f","3cc9365f-7801-411b-89e6-31077e15378c","bb572628-9074-450a-84e1-8ee7ac2620dd","c890aa4e-4e8b-4bd2-b120-cf6d20c095c1","bb2d48a0-55ee-4019-b28e-2f979cb91f0a","9110d549-d3d3-43d0-8c40-98027a6e475d","edbf327e-22f5-436d-8ffc-a50ef3ad90ae","5909313a-57f3-4b4d-a669-4f7270d435f0","1b6441aa-40f2-4ef4-90ed-653430d34037","348eecbd-934e-4f07-b43f-03327c303337","e1cbd84b-880a-4937-b473-fe78e1b67eef","da1fc584-1877-4a4e-98be-74f902e0af98","70e3bcdf-5651-4d89-b493-bebea3696f28","d8fc3fb9-f4c9-4cef-9a1b-e86d772ad799","acbef404-a65d-404e-8f36-e5cb65240dba","574e5027-b26e-4ea0-89dd-05d62f717ebd","70dce698-2c1b-44c6-a306-ef90f7442cbd","cd193184-aa18-4d97-b472-6c7d0d49cf22","bf1b8f19-b9bb-47f5-be1a-29276eb0b01d","5522019e-f49d-4e8d-a27d-138418290db6","b9c00fb2-8547-4f5b-8acb-849c4d0e4c4e","a287c35d-e430-449d-bced-c4fc7573d292","a1f53d13-9822-4344-a2e7-9e2dfda8d0bd","fc218291-c460-48a7-a19b-239d645f1255","ab53b9b0-fcc2-434b-bf70-67b11388f861","4591992d-87f8-49c8-bb94-7ce12c03bff4","4dcc47ae-ec8e-4e31-aa27-41ff5a74cdb9","970fd873-725a-40e8-8cc5-90d8a9833f0d","2b817cb3-eaa3-4abb-8f33-db65a6119811","9992cd8b-87aa-427c-ae64-fd5c260e42da","604338ad-c8ed-4f2d-a166-f6c2dc937f6b","bcfa8814-1268-417e-931c-7d87e914ae27","b73981d9-812c-42a1-8f12-243428eda8ed","27c59525-8a8c-4006-890e-3c8b140c57ed","ac9045a7-49a7-4ccd-91dc-972f46ee1909","fc59deae-a349-4e62-9b42-986b20f69645","bb1fd637-5e7e-491b-9a57-ea1c4b6115b9","fe6778d1-324a-4633-a8b2-cb80b9a2345e","032c21fe-dabc-40f4-be73-9e98b242cf8a","cf84dcc5-c4f9-463c-9d1a-56843b773bf5","8ae2f905-a649-44e6-94d2-cb3cfae7007f","9355b377-2dae-4683-98f6-69a220a9aece","c779947a-e76c-4e22-82c2-9d032e9c4797","701b3e42-ad51-4bb9-bfd1-f51712619882","cdc4a618-a328-4e6f-b593-fd8b6de86c73","b841b560-bb41-44ab-b3c9-bca8d3b441d4","65c45cac-8c0d-4c4e-ae06-4b7edf3a9c3d","dabfba89-4616-412d-8f8e-7344b23469e1","13c8d82c-18b7-4eca-98be-c1412057e965","ef425645-faa7-4249-aa5b-4cb2ac36f30a","ed5d2635-15d1-426c-b50c-f50bc84ecfe8","7b62a9d4-3de7-4ba3-94ee-9693447f6de3","d29d70e1-a6cf-4fb7-99d2-ee3823dc28c6","fae2fdbc-e79a-421f-bf24-a9395b131b86","b47b8e05-a109-475c-99b9-0ed9596ec6d2","95b3bf1d-b3d6-4aec-9555-00674082e53d","9cc7d12e-9355-4335-b265-f813fae9c5f7","a570ff5e-d4ce-4ef2-9fa1-6924fdd9cd1f","b643ac16-0591-45b9-ad37-7b6b60b1a01e","93ef9497-a2e7-452f-985a-563a021eb47c","50fc1ef5-1242-4f18-ae3c-a97152737845","b83b67bc-ed10-4eaa-ac5f-686ac36d49ce","6b4b3913-5fd4-48cd-964d-a18720f4d297","f1f20221-8f79-4737-a527-ebd56b0fa8d3","0610ff1c-c119-4295-b36a-7e8117ee38c5","1d13f597-141e-4426-ad02-aa9b69fd68e6","25677321-009e-4a9a-acb8-e79dc2c5b45d","03df1634-56a5-4a47-8646-91f3d6032eb0","63082208-00d3-41dd-b0ba-adfd3794c9d6","e8c55e41-b1c2-4a2d-96ed-4ead437558cf","a6b4ab4d-86bc-49a3-83d3-2bdd0b348cad","80c75dff-bbbc-4a2f-8bba-b5118c2f91ad","481b6135-9313-4a56-90e0-092d61f794cb","aa718d5a-ab1b-4d53-80aa-8874f10bf0f5","f418364e-f36e-46d5-9bb0-20fd02c886bf","848bb57e-f69c-4716-86cd-79d83b465110","b8cc1833-7e93-44a1-89f1-6e56ffb21657","0e5f8906-0d7b-4084-b2b3-fbc908e98b59","ac79660c-5c72-4ebf-a167-71a3891c3f2b","c721d6c5-86e7-4556-9bc7-de85e0bcc330","2c76c89e-cb56-438d-9859-6127869bd459","c6586382-1b05-46e3-9b3a-0d1fb17b4b5e","b23c9a46-a040-4140-8acb-2dc3add0b0dc","9cd74b51-a6f3-44ee-8cf1-b8758a9146ce","a2c45c2b-c999-4bd1-93ba-1a7cbfee5b36","bc5e35e3-be9e-425f-b1a4-742286d7924a","6d52c5d6-2aaf-4d89-8ad0-ceba80efd903","ba78d23c-4bf6-458a-9379-86d9af3c268a","220ef235-283b-4e8b-ad6c-a9467c7c91cd","df9e48a9-7dee-4012-96e0-2534c8518f39","2e9fb20f-03d5-4427-a28c-8f02427ca02e","86558bbf-283d-4126-a2fb-d1884a8a938e","a2c44c7f-975a-439c-a47b-841e3921d1a7","2956286a-a232-4820-99c8-c9fd4c307182","639d9f20-0fab-4e75-acfe-af995d9b9434","e23a34ec-d505-4cdb-86fe-1e4b82d32072","45c565fa-95d1-4dba-abb5-9a80d1d2a493","ae01af56-fa53-4ce5-965c-bc1210a645e9","84039c01-ee09-4c49-a9dc-5f425e9b97fd","91635917-fdca-406d-bf3b-382c1765e3f8","ec70b5e2-baa8-4432-9468-a92a469a6843","ab654ab4-2f3a-4d3a-923e-68c060cf31b8","79247fa9-4d53-4a8c-ab28-40ac3d768e39","e9cbabbb-d571-42eb-a62d-64c952348cde","eed49f33-5d7b-4f6f-bfcd-6456c8c73133"],"created_time":1645635780000,"last_edited_time":1645635840000,"parent_id":"41249f3f-76a2-458a-b13d-2bc06310337b","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"41249f3f-76a2-458a-b13d-2bc06310337b":{"role":"reader","value":{"id":"41249f3f-76a2-458a-b13d-2bc06310337b","version":174,"type":"page","properties":{"title":[["deep learning engineer manual"]]},"content":["4ffbb2cd-f634-421a-9e5a-9f2758193609","e9d171d8-17bc-4aa6-88f7-79391cf072d1","fcd4d688-6b0e-4ee7-8838-53a4d48a0af4","94cea945-881b-4d6b-be5c-505834b715db","4f6aae13-77aa-40ad-a5fb-7db5b90c3ae3","f9e18efc-827a-4f89-a8fc-e8975dcadc02"],"permissions":[{"role":"editor","type":"user_permission","user_id":"9e9c4442-4350-473a-b900-c954b0bd7a95"}],"created_time":1645559700000,"last_edited_time":1645644420000,"parent_id":"bd32b787-e471-49f3-8941-174a9c6846b6","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bd32b787-e471-49f3-8941-174a9c6846b6":{"role":"reader","value":{"id":"bd32b787-e471-49f3-8941-174a9c6846b6","version":162,"type":"page","properties":{"title":[["Yihui He’s Blog"]]},"content":["cc62526f-e4eb-42e5-8e8f-a22c3abd7b46","eb534ff0-d0e6-4c83-b817-92c761ad9034","41249f3f-76a2-458a-b13d-2bc06310337b","09ac442d-d3b5-4f43-9531-90cdae7640b7","fad54c70-af5c-42a3-a00a-ff18bea9c382","9abe926f-8b36-4a60-a77e-e5436690a8c0","84c674a7-bbe3-4ac5-88c7-68e0c3909585","60ff1c6d-fde5-426d-ac57-7bba2a5296a2","daf31581-086b-4fb1-9695-5a79117d4300","95728d67-dc1f-4086-881b-1cd1bf72f985","3db8e8fd-7383-4aea-8beb-608282db050e","38a364d6-720a-4788-aeee-c2b224745860","1e36e1bc-8271-4348-8cff-6b959e7482df"],"discussions":["a13be18e-5008-4f8c-b07a-0fadb99d7450"],"format":{"page_icon":"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/63e89fe9-f5cd-4414-be0e-53d91aa54fc3/me_small.jpg"},"permissions":[{"role":"editor","type":"user_permission","user_id":"9e9c4442-4350-473a-b900-c954b0bd7a95"},{"role":"reader","type":"public_permission","added_timestamp":1645466303668}],"created_time":1645422720000,"last_edited_time":1645645260000,"parent_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1","parent_table":"space","alive":true,"file_ids":["e3d85759-49f2-40d2-ba30-d25ca401872e","cfc564cc-91ae-4a96-a912-fcc9a28ec5db","63e89fe9-f5cd-4414-be0e-53d91aa54fc3"],"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"c24004db-f73b-44e5-b8fa-44ebcf22447a":{"role":"reader","value":{"id":"c24004db-f73b-44e5-b8fa-44ebcf22447a","version":2,"type":"text","properties":{"title":[["In traditional software engineering, a bug usually leads to the program crashing. While this is annoying for the user, it is critical for the developer to inspect the errors to understand why. With deep learning, we sometimes encounter errors, but all too often, the program crashes without a clear reason why. While these issues can be debugged manually, deep learning models most often fail because of poor output predictions. What’s worse is that when the model performance is low, there is usually no signal about why or when the models failed."]]},"created_time":1645635848559,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6723210b-5c98-40ad-b479-2473a93ea4be":{"role":"reader","value":{"id":"6723210b-5c98-40ad-b479-2473a93ea4be","version":2,"type":"text","properties":{"title":[["A common sentiment among practitioners is that they spend "],["80–90% of time debugging and tuning the models",[["b"]]],[" and only 10–20% of time deriving math equations and implementing things. This is confirmed by Andrej Kaparthy, "],["as seen in this tweet",[["b"],["_"],["a","https://twitter.com/karpathy/status/423990618289733632"]]],["."]]},"created_time":1645635848559,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"68839e03-5ecf-47ee-9ed4-cceb22350031":{"role":"reader","value":{"id":"68839e03-5ecf-47ee-9ed4-cceb22350031","version":2,"type":"sub_sub_header","properties":{"title":[["1 - Why Is Deep Learning Troubleshooting Hard?"]]},"created_time":1645635848559,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6c1553da-9d24-4e84-b386-06f7e53c4c19":{"role":"reader","value":{"id":"6c1553da-9d24-4e84-b386-06f7e53c4c19","version":2,"type":"text","properties":{"title":[["Suppose you are trying to reproduce a research paper result for your work, but your results are worse. You might wonder why your model’s performance is significantly worse than the paper that you’re trying to reproduce?"]]},"created_time":1645635848560,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"39a7abde-b07d-4436-8dae-4f48261a582a":{"role":"reader","value":{"id":"39a7abde-b07d-4436-8dae-4f48261a582a","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image3.png"]]},"created_time":1645635848560,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"54e72d65-b5db-49d3-bd40-26e623712f6d":{"role":"reader","value":{"id":"54e72d65-b5db-49d3-bd40-26e623712f6d","version":2,"type":"text","properties":{"title":[["Many different things can cause this:"]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"7b51d6b5-38b5-4fe4-99d6-5ee9bcddb8ca":{"role":"reader","value":{"id":"7b51d6b5-38b5-4fe4-99d6-5ee9bcddb8ca","version":2,"type":"bulleted_list","properties":{"title":[["It can be "],["implementation bugs",[["b"]]],[". Most bugs in deep learning are actually invisible."]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"2288e49d-eac9-4238-a3ed-953c8ed31067":{"role":"reader","value":{"id":"2288e49d-eac9-4238-a3ed-953c8ed31067","version":2,"type":"bulleted_list","properties":{"title":[["Hyper-parameter choices",[["b"]]],[" can also cause your performance to degrade. Deep learning models are very sensitive to hyper-parameters. Even very subtle choices of learning rate and weight initialization can make a big difference."]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"15662054-e89e-468f-927f-2e21471fb714":{"role":"reader","value":{"id":"15662054-e89e-468f-927f-2e21471fb714","version":2,"type":"bulleted_list","properties":{"title":[["Performance can also be worse just because of "],["data/model fit",[["b"]]],[". For example, you pre-train your model on ImageNet data and fit it on self-driving car images, which are harder to learn."]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"dd3420dd-f5ca-47c2-b331-dbd41e5a90b0":{"role":"reader","value":{"id":"dd3420dd-f5ca-47c2-b331-dbd41e5a90b0","version":2,"type":"bulleted_list","properties":{"title":[["Finally, poor model performance could be caused not by your model but your "],["dataset construction",[["b"]]],[". Typical issues here include not having enough examples, dealing with noisy labels and imbalanced classes, splitting train and test set with different distributions."]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"d426685f-885d-4e12-873e-6b0f0ca7bf26":{"role":"reader","value":{"id":"d426685f-885d-4e12-873e-6b0f0ca7bf26","version":2,"type":"sub_sub_header","properties":{"title":[["2 - Strategy to Debug Neural Networks"]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"1d5ff9ae-0e8a-4eb3-a222-26f312aa742f":{"role":"reader","value":{"id":"1d5ff9ae-0e8a-4eb3-a222-26f312aa742f","version":2,"type":"text","properties":{"title":[["The key idea of deep learning troubleshooting is: "],["Since it is hard to disambiguate errors, it’s best to start simple and gradually ramp up complexity.",[["i"]]]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"7cecfe4a-c842-45f5-b781-983f1e5927cd":{"role":"reader","value":{"id":"7cecfe4a-c842-45f5-b781-983f1e5927cd","version":2,"type":"text","properties":{"title":[["This lecture provides "],["a decision tree for debugging deep learning models and improving performance",[["b"]]],[". This guide assumes that you already have an initial test dataset, a single metric to improve, and target performance based on human-level performance, published results, previous baselines, etc."]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"5ffa3a3f-1fef-494e-92cb-65365731d36b":{"role":"reader","value":{"id":"5ffa3a3f-1fef-494e-92cb-65365731d36b","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image4.png"]]},"created_time":1645635848575,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"110aa3e0-e62d-4462-abcb-63214a331990":{"role":"reader","value":{"id":"110aa3e0-e62d-4462-abcb-63214a331990","version":2,"type":"sub_sub_header","properties":{"title":[["3 - Start Simple"]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"11ee9a31-d8af-40d1-be25-d9e383106893":{"role":"reader","value":{"id":"11ee9a31-d8af-40d1-be25-d9e383106893","version":2,"type":"text","properties":{"title":[["The first step is the troubleshooting workflow is "],["starting simple",[["b"]]],["."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"9b583af0-299b-42ae-a402-ea3415241aa3":{"role":"reader","value":{"id":"9b583af0-299b-42ae-a402-ea3415241aa3","version":2,"type":"sub_sub_header","properties":{"title":[["Choose A Simple Architecture",[["b"]]]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"45296e7e-335d-4a0b-85a9-97c8bdc9ad95":{"role":"reader","value":{"id":"45296e7e-335d-4a0b-85a9-97c8bdc9ad95","version":2,"type":"text","properties":{"title":[["There are a few things to consider when you want to start simple. The first is how to "],["choose a simple architecture",[["b"]]],[". These are architectures that are easy to implement and are likely to get you part of the way towards solving your problem without introducing as many bugs."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"3cb83298-ecae-4099-921d-54f8506ab574":{"role":"reader","value":{"id":"3cb83298-ecae-4099-921d-54f8506ab574","version":2,"type":"text","properties":{"title":[["Architecture selection is one of the many intimidating parts of getting into deep learning because there are tons of papers coming out all-the-time and claiming to be state-of-the-art on some problems. They get very complicated fast. In the limit, if you’re trying to get to maximal performance, then architecture selection is challenging. But when starting on a new problem, you can just solve a simple set of rules that will allow you to pick an architecture that enables you to do a decent job on the problem you’re working on."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"2dd503b0-148f-4462-bf44-2a6b41a115e8":{"role":"reader","value":{"id":"2dd503b0-148f-4462-bf44-2a6b41a115e8","version":2,"type":"bulleted_list","properties":{"title":[["If your data looks like "],["images",[["b"]]],[", start with a LeNet-like architecture and consider using something like ResNet as your codebase gets more mature."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"421b58db-a38c-4a72-abc1-0daddd457ef6":{"role":"reader","value":{"id":"421b58db-a38c-4a72-abc1-0daddd457ef6","version":2,"type":"bulleted_list","properties":{"title":[["If your data looks like "],["sequences",[["b"]]],[", start with an LSTM with one hidden layer and/or temporal/classical convolutions. Then, when your problem gets more mature, you can move to an Attention-based model or a WaveNet-like model."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"8c46d42c-7c84-41db-9b04-aff2690d57dd":{"role":"reader","value":{"id":"8c46d42c-7c84-41db-9b04-aff2690d57dd","version":2,"type":"bulleted_list","properties":{"title":[["For "],["all other tasks",[["b"]]],[", start with a fully-connected neural network with one hidden layer and use more advanced networks later, depending on the problem."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"cf60285a-7072-470f-b5af-dfa826d1f815":{"role":"reader","value":{"id":"cf60285a-7072-470f-b5af-dfa826d1f815","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image7.png"]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"63aab68c-724a-4e21-9521-6e206d91f30f":{"role":"reader","value":{"id":"63aab68c-724a-4e21-9521-6e206d91f30f","version":2,"type":"text","properties":{"title":[["In reality, many times, the input data contains multiple of those things above. So how to deal with "],["multiple input modalities",[["b"]]],[" into a neural network? Here is the 3-step strategy that we recommend:"]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"87c13323-5e3f-4fb8-b22c-5ed8fd46f55e":{"role":"reader","value":{"id":"87c13323-5e3f-4fb8-b22c-5ed8fd46f55e","version":2,"type":"bulleted_list","properties":{"title":[["First, map each of these modalities into a lower-dimensional feature space. In the example above, the images are passed through a ConvNet, and the words are passed through an LSTM."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"332bf8c1-7241-4974-8915-37dfb9ec5cad":{"role":"reader","value":{"id":"332bf8c1-7241-4974-8915-37dfb9ec5cad","version":2,"type":"bulleted_list","properties":{"title":[["Then we flatten the outputs of those networks to get a single vector for each of the inputs that will go into the model. Then we concatenate those inputs."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"8591cffe-baf4-4b81-9cd0-a13fd4689170":{"role":"reader","value":{"id":"8591cffe-baf4-4b81-9cd0-a13fd4689170","version":2,"type":"bulleted_list","properties":{"title":[["Finally, we pass them through some fully-connected layers to an output."]]},"created_time":1645635848576,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a6572d92-a001-4d6c-8f31-2742d62c83b5":{"role":"reader","value":{"id":"a6572d92-a001-4d6c-8f31-2742d62c83b5","version":2,"type":"sub_sub_header","properties":{"title":[["Use Sensible Defaults",[["b"]]]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"758d2874-8f6c-45b8-aaa7-542bd87017ea":{"role":"reader","value":{"id":"758d2874-8f6c-45b8-aaa7-542bd87017ea","version":2,"type":"text","properties":{"title":[["After choosing a simple architecture, the next thing to do is to "],["select sensible hyper-parameter defaults",[["b"]]],[" to start with. Here are the defaults that we recommend:"]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"49e7e5b6-62da-4616-b687-766a24bb7c34":{"role":"reader","value":{"id":"49e7e5b6-62da-4616-b687-766a24bb7c34","version":2,"type":"bulleted_list","properties":{"title":[["Adam optimizer with a “magic” learning rate value of 3e-4",[["b"],["_"],["a","https://twitter.com/karpathy/status/801621764144971776?lang=en"]]],["."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ffbb1023-d94c-4188-a369-d7400282ae82":{"role":"reader","value":{"id":"ffbb1023-d94c-4188-a369-d7400282ae82","version":2,"type":"bulleted_list","properties":{"title":[["ReLU",[["b"],["_"],["a","https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it"]]],[" activation for fully-connected and convolutional models and "],["Tanh",[["b"],["_"],["a","https://stats.stackexchange.com/questions/330559/why-is-tanh-almost-always-better-than-sigmoid-as-an-activation-function"]]],[" activation for LSTM models."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"70107c2c-bcaa-476f-b19c-3ff93fc8b0a5":{"role":"reader","value":{"id":"70107c2c-bcaa-476f-b19c-3ff93fc8b0a5","version":2,"type":"bulleted_list","properties":{"title":[["He initialization for ReLU activation function and Glorot initialization for Tanh activation function",[["b"],["_"],["a","https://datascience.stackexchange.com/questions/13061/when-to-use-he-or-glorot-normal-initialization-over-uniform-init-and-what-are"]]],["."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"040da977-2daa-46dc-b2bb-ef9e7a2e2d8e":{"role":"reader","value":{"id":"040da977-2daa-46dc-b2bb-ef9e7a2e2d8e","version":2,"type":"bulleted_list","properties":{"title":[["No regularization and data normalization."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"d4cbc4ee-17a5-4809-9617-3c619b183ab1":{"role":"reader","value":{"id":"d4cbc4ee-17a5-4809-9617-3c619b183ab1","version":2,"type":"sub_sub_header","properties":{"title":[["Normalize Inputs",[["b"]]]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6ec5176f-12ab-4ba1-b68d-e5ad92bfdc2e":{"role":"reader","value":{"id":"6ec5176f-12ab-4ba1-b68d-e5ad92bfdc2e","version":2,"type":"text","properties":{"title":[["The next step is to "],["normalize the input data",[["b"]]],[", subtracting the mean and dividing by the variance. Note that for images, it’s fine to scale values to [0, 1] or [-0.5, 0.5] (for example, by dividing by 255)."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b0ed0084-810e-4102-be24-5302081e77b0":{"role":"reader","value":{"id":"b0ed0084-810e-4102-be24-5302081e77b0","version":2,"type":"sub_sub_header","properties":{"title":[["Simplify The Problem",[["b"]]]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"302aa177-e89d-4459-93c0-0a1b1885b175":{"role":"reader","value":{"id":"302aa177-e89d-4459-93c0-0a1b1885b175","version":2,"type":"text","properties":{"title":[["The final thing you should do is consider "],["simplifying the problem",[["b"]]],[" itself. If you have a complicated problem with massive data and tons of classes to deal with, then you should consider:"]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"84d20986-5210-4788-ab78-c12e3d0026d4":{"role":"reader","value":{"id":"84d20986-5210-4788-ab78-c12e3d0026d4","version":2,"type":"bulleted_list","properties":{"title":[["Working with a small training set around 10,000 examples."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ecb4f151-df95-446f-91d9-50fc48616b45":{"role":"reader","value":{"id":"ecb4f151-df95-446f-91d9-50fc48616b45","version":2,"type":"bulleted_list","properties":{"title":[["Using a fixed number of objects, classes, input size, etc."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"9b8d5c45-47d4-4bd9-8828-978b0bac97b6":{"role":"reader","value":{"id":"9b8d5c45-47d4-4bd9-8828-978b0bac97b6","version":2,"type":"bulleted_list","properties":{"title":[["Creating a simpler synthetic training set like in research labs."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"7236441c-8d2f-4e39-ae2e-d5f011826f8a":{"role":"reader","value":{"id":"7236441c-8d2f-4e39-ae2e-d5f011826f8a","version":2,"type":"text","properties":{"title":[["This is important because (1) you will have reasonable confidence that your model should be able to solve, and (2) your iteration speed will increase."]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"aed72b91-5b25-42a5-8dd3-ef834bba4e3e":{"role":"reader","value":{"id":"aed72b91-5b25-42a5-8dd3-ef834bba4e3e","version":2,"type":"text","properties":{"title":[["The diagram below neatly summarizes how to start simple:"]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"8dd5db24-6ba7-4ec0-8b6e-dc300f218942":{"role":"reader","value":{"id":"8dd5db24-6ba7-4ec0-8b6e-dc300f218942","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image6.png"]]},"created_time":1645635848577,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"4fb20f9d-6618-4895-87a5-5c2680c65758":{"role":"reader","value":{"id":"4fb20f9d-6618-4895-87a5-5c2680c65758","version":2,"type":"sub_sub_header","properties":{"title":[["4 - Implement and Debug"]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6f8d56f1-586d-4493-b87d-c04356c2053f":{"role":"reader","value":{"id":"6f8d56f1-586d-4493-b87d-c04356c2053f","version":2,"type":"text","properties":{"title":[["To give you a preview, below are the five most common bugs in deep learning models that we recognize:"]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"3cc9365f-7801-411b-89e6-31077e15378c":{"role":"reader","value":{"id":"3cc9365f-7801-411b-89e6-31077e15378c","version":2,"type":"bulleted_list","properties":{"title":[["Incorrect shapes for the network tensors",[["b"]]],[": This bug is a common one and can fail silently. This happens many times because the automatic differentiation systems in the deep learning framework do silent broadcasting. Tensors become different shapes in the network and can cause a lot of problems."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bb572628-9074-450a-84e1-8ee7ac2620dd":{"role":"reader","value":{"id":"bb572628-9074-450a-84e1-8ee7ac2620dd","version":2,"type":"bulleted_list","properties":{"title":[["Pre-processing inputs incorrectly",[["b"]]],[": For example, you forget to normalize your inputs or apply too much input pre-processing (over-normalization and excessive data augmentation)."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"c890aa4e-4e8b-4bd2-b120-cf6d20c095c1":{"role":"reader","value":{"id":"c890aa4e-4e8b-4bd2-b120-cf6d20c095c1","version":2,"type":"bulleted_list","properties":{"title":[["Incorrect input to the model’s loss function",[["b"]]],[": For example, you use softmax outputs to a loss that expects logits."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bb2d48a0-55ee-4019-b28e-2f979cb91f0a":{"role":"reader","value":{"id":"bb2d48a0-55ee-4019-b28e-2f979cb91f0a","version":2,"type":"bulleted_list","properties":{"title":[["Forgot to set up train mode for the network correctly",[["b"]]],[": For example, toggling train/evaluation mode or controlling batch norm dependencies."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"9110d549-d3d3-43d0-8c40-98027a6e475d":{"role":"reader","value":{"id":"9110d549-d3d3-43d0-8c40-98027a6e475d","version":2,"type":"bulleted_list","properties":{"title":[["Numerical instability",[["b"]]],[": For example, you get `inf` or `NaN` as outputs. This bug often stems from using an exponent, a log, or a division operation somewhere in the code."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"edbf327e-22f5-436d-8ffc-a50ef3ad90ae":{"role":"reader","value":{"id":"edbf327e-22f5-436d-8ffc-a50ef3ad90ae","version":2,"type":"text","properties":{"title":[["Here are three pieces of general advice for implementing your model:"]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"5909313a-57f3-4b4d-a669-4f7270d435f0":{"role":"reader","value":{"id":"5909313a-57f3-4b4d-a669-4f7270d435f0","version":2,"type":"bulleted_list","properties":{"title":[["Start with a lightweight implementation",[["b"]]],[". You want minimum possible new lines of code for the 1st version of your model. The rule of thumb is less than 200 lines. This doesn’t count tested infrastructure components or TensorFlow/PyTorch code."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"1b6441aa-40f2-4ef4-90ed-653430d34037":{"role":"reader","value":{"id":"1b6441aa-40f2-4ef4-90ed-653430d34037","version":2,"type":"bulleted_list","properties":{"title":[["Use off-the-shelf components",[["b"]]],[" such as Keras if possible, since most of the stuff in Keras works well out-of-the-box. If you have to use TensorFlow, use the built-in functions, don’t do the math yourself. This would help you avoid a lot of numerical instability issues."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"348eecbd-934e-4f07-b43f-03327c303337":{"role":"reader","value":{"id":"348eecbd-934e-4f07-b43f-03327c303337","version":2,"type":"bulleted_list","properties":{"title":[["Build complicated data pipelines later",[["b"]]],[". These are important for large-scale ML systems, but you should not start with them because data pipelines themselves can be a big source of bugs. Just start with a dataset that you can load into memory."]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e1cbd84b-880a-4937-b473-fe78e1b67eef":{"role":"reader","value":{"id":"e1cbd84b-880a-4937-b473-fe78e1b67eef","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image11.png"]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"da1fc584-1877-4a4e-98be-74f902e0af98":{"role":"reader","value":{"id":"da1fc584-1877-4a4e-98be-74f902e0af98","version":2,"type":"sub_sub_header","properties":{"title":[["Get Your Model To Run",[["b"]]]]},"created_time":1645635848578,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"70e3bcdf-5651-4d89-b493-bebea3696f28":{"role":"reader","value":{"id":"70e3bcdf-5651-4d89-b493-bebea3696f28","version":2,"type":"text","properties":{"title":[["The first step of implementing bug-free deep learning models is "],["getting your model to run at all",[["b"]]],[". There are a few things that can prevent this from happening:"]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"d8fc3fb9-f4c9-4cef-9a1b-e86d772ad799":{"role":"reader","value":{"id":"d8fc3fb9-f4c9-4cef-9a1b-e86d772ad799","version":2,"type":"bulleted_list","properties":{"title":[["Shape mismatch/casting issue",[["b"]]],[": To address this type of problem, you should step through your model creation and inference step-by-step in a debugger, checking for correct shapes and data types of your tensors."]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"acbef404-a65d-404e-8f36-e5cb65240dba":{"role":"reader","value":{"id":"acbef404-a65d-404e-8f36-e5cb65240dba","version":2,"type":"bulleted_list","properties":{"title":[["Out-of-memory issues",[["b"]]],[": This can be very difficult to debug. You can scale back your memory-intensive operations one-by-one. For example, if you create large matrices anywhere in your code, you can reduce the size of their dimensions or cut your batch size in half."]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"574e5027-b26e-4ea0-89dd-05d62f717ebd":{"role":"reader","value":{"id":"574e5027-b26e-4ea0-89dd-05d62f717ebd","version":2,"type":"bulleted_list","properties":{"title":[["Other issues",[["b"]]],[": You can simply Google it. Stack Overflow would be great most of the time."]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"70dce698-2c1b-44c6-a306-ef90f7442cbd":{"role":"reader","value":{"id":"70dce698-2c1b-44c6-a306-ef90f7442cbd","version":2,"type":"text","properties":{"title":[["Let’s zoom in on the process of stepping through model creation in a debugger and talk about "],["debuggers for deep learning code",[["b"]]],[":"]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"cd193184-aa18-4d97-b472-6c7d0d49cf22":{"role":"reader","value":{"id":"cd193184-aa18-4d97-b472-6c7d0d49cf22","version":2,"type":"bulleted_list","properties":{"title":[["In PyTorch, you can use "],["ipdb",[["b"],["_"],["a","https://pypi.org/project/ipdb/"]]],[" — which exports functions to access the interactive "],["IPython",[["b"],["_"],["a","https://ipython.org/"]]],[" debugger."]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bf1b8f19-b9bb-47f5-be1a-29276eb0b01d":{"role":"reader","value":{"id":"bf1b8f19-b9bb-47f5-be1a-29276eb0b01d","version":2,"type":"bulleted_list","properties":{"title":[["In TensorFlow, it’s trickier. TensorFlow separates the process of creating the graph and executing operations in the graph. There are three options you can try: (1) step through the graph creation itself and inspect each tensor layer, (2) step into the training loop and evaluate the tensor layers, or (3) use "],["TensorFlow Debugger",[["b"],["_"],["a","https://mullikine.github.io/posts/tensorflow-debugger-tfdb-and-emacs/"]]],[" (tfdb), which does option 1 and 2 automatically."]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"5522019e-f49d-4e8d-a27d-138418290db6":{"role":"reader","value":{"id":"5522019e-f49d-4e8d-a27d-138418290db6","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image14.png"]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b9c00fb2-8547-4f5b-8acb-849c4d0e4c4e":{"role":"reader","value":{"id":"b9c00fb2-8547-4f5b-8acb-849c4d0e4c4e","version":2,"type":"sub_sub_header","properties":{"title":[["Overfit A Single Batch",[["b"]]]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a287c35d-e430-449d-bced-c4fc7573d292":{"role":"reader","value":{"id":"a287c35d-e430-449d-bced-c4fc7573d292","version":2,"type":"text","properties":{"title":[["After getting your model to run, the next thing you need to do is to "],["overfit a single batch of data",[["b"]]],[". This is a heuristic that can catch an absurd number of bugs. This really means that you want to drive your training error arbitrarily close to 0."]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a1f53d13-9822-4344-a2e7-9e2dfda8d0bd":{"role":"reader","value":{"id":"a1f53d13-9822-4344-a2e7-9e2dfda8d0bd","version":2,"type":"text","properties":{"title":[["There are a few things that can happen when you try to overfit a single batch and it fails:"]]},"created_time":1645635848579,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"fc218291-c460-48a7-a19b-239d645f1255":{"role":"reader","value":{"id":"fc218291-c460-48a7-a19b-239d645f1255","version":2,"type":"bulleted_list","properties":{"title":[["Error goes up",[["b"]]],[": Commonly, this is due to a flip sign somewhere in the loss function/gradient."]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ab53b9b0-fcc2-434b-bf70-67b11388f861":{"role":"reader","value":{"id":"ab53b9b0-fcc2-434b-bf70-67b11388f861","version":2,"type":"bulleted_list","properties":{"title":[["Error explodes",[["b"]]],[": This is usually a numerical issue but can also be caused by a high learning rate."]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"4591992d-87f8-49c8-bb94-7ce12c03bff4":{"role":"reader","value":{"id":"4591992d-87f8-49c8-bb94-7ce12c03bff4","version":2,"type":"bulleted_list","properties":{"title":[["Error oscillates",[["b"]]],[": You can lower the learning rate and inspect the data for shuffled labels or incorrect data augmentation."]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"4dcc47ae-ec8e-4e31-aa27-41ff5a74cdb9":{"role":"reader","value":{"id":"4dcc47ae-ec8e-4e31-aa27-41ff5a74cdb9","version":2,"type":"bulleted_list","properties":{"title":[["Error plateaus",[["b"]]],[": You can increase the learning rate and get rid of regulation. Then you can inspect the loss function and the data pipeline for correctness."]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"970fd873-725a-40e8-8cc5-90d8a9833f0d":{"role":"reader","value":{"id":"970fd873-725a-40e8-8cc5-90d8a9833f0d","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image10.png"]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"2b817cb3-eaa3-4abb-8f33-db65a6119811":{"role":"reader","value":{"id":"2b817cb3-eaa3-4abb-8f33-db65a6119811","version":2,"type":"sub_sub_header","properties":{"title":[["Compare To A Known Result",[["b"]]]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"9992cd8b-87aa-427c-ae64-fd5c260e42da":{"role":"reader","value":{"id":"9992cd8b-87aa-427c-ae64-fd5c260e42da","version":2,"type":"text","properties":{"title":[["Once your model overfits in a single batch, there can still be some other issues that cause bugs. The last step here is to "],["compare your results to a known result",[["b"]]],[". So what sort of known results are useful?"]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"604338ad-c8ed-4f2d-a166-f6c2dc937f6b":{"role":"reader","value":{"id":"604338ad-c8ed-4f2d-a166-f6c2dc937f6b","version":2,"type":"bulleted_list","properties":{"title":[["The most useful results come from "],["an official model implementation evaluated on a similar dataset to yours",[["b"]]],[". You can step through the code in both models line-by-line and ensure your model has the same output. You want to ensure that your model performance is up to par with expectations."]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bcfa8814-1268-417e-931c-7d87e914ae27":{"role":"reader","value":{"id":"bcfa8814-1268-417e-931c-7d87e914ae27","version":2,"type":"bulleted_list","properties":{"title":[["If you can’t find an official implementation on a similar dataset, you can compare your approach to results from "],["an official model implementation evaluated on a benchmark dataset",[["b"]]],[". You most definitely want to walk through the code line-by-line and ensure you have the same output."]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b73981d9-812c-42a1-8f12-243428eda8ed":{"role":"reader","value":{"id":"b73981d9-812c-42a1-8f12-243428eda8ed","version":2,"type":"bulleted_list","properties":{"title":[["If there is no official implementation of your approach, you can compare it to results from "],["an unofficial model implementation",[["b"]]],[". You can review the code the same as before but with lower confidence (because almost all the unofficial implementations on GitHub have bugs)."]]},"created_time":1645635848580,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"27c59525-8a8c-4006-890e-3c8b140c57ed":{"role":"reader","value":{"id":"27c59525-8a8c-4006-890e-3c8b140c57ed","version":2,"type":"bulleted_list","properties":{"title":[["Then, you can compare to results from "],["a paper with no code",[["b"]]],[" (to ensure that your performance is up to par with expectations), results from "],["your model on a benchmark dataset",[["b"]]],[" (to make sure your model performs well in a simpler setting), and results from "],["a similar model on a similar dataset",[["b"]]],[" (to help you get a general sense of what kind of performance can be expected)."]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ac9045a7-49a7-4ccd-91dc-972f46ee1909":{"role":"reader","value":{"id":"ac9045a7-49a7-4ccd-91dc-972f46ee1909","version":2,"type":"bulleted_list","properties":{"title":[["An under-rated source of results comes from "],["simple baselines",[["b"]]],[" (for example, the average of outputs or linear regression), which can help make sure that your model is learning anything at all."]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"fc59deae-a349-4e62-9b42-986b20f69645":{"role":"reader","value":{"id":"fc59deae-a349-4e62-9b42-986b20f69645","version":2,"type":"text","properties":{"title":[["The diagram below neatly summarizes how to implement and debug deep neural networks:"]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bb1fd637-5e7e-491b-9a57-ea1c4b6115b9":{"role":"reader","value":{"id":"bb1fd637-5e7e-491b-9a57-ea1c4b6115b9","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image8.png"]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"fe6778d1-324a-4633-a8b2-cb80b9a2345e":{"role":"reader","value":{"id":"fe6778d1-324a-4633-a8b2-cb80b9a2345e","version":2,"type":"sub_sub_header","properties":{"title":[["5 - Evaluate"]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"032c21fe-dabc-40f4-be73-9e98b242cf8a":{"role":"reader","value":{"id":"032c21fe-dabc-40f4-be73-9e98b242cf8a","version":2,"type":"sub_sub_header","properties":{"title":[["Bias-Variance Decomposition",[["b"]]]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"cf84dcc5-c4f9-463c-9d1a-56843b773bf5":{"role":"reader","value":{"id":"cf84dcc5-c4f9-463c-9d1a-56843b773bf5","version":2,"type":"text","properties":{"title":[["To evaluate models and prioritize the next steps in model development, we will apply the bias-variance decomposition. The "],["bias-variance decomposition",[["b"],["_"],["a","http://scott.fortmann-roe.com/docs/BiasVariance.html"]]],[" is the fundamental model fitting tradeoff. In our application, let’s talk more specifically about the formula for bias-variance tradeoff with respect to the "],["test error;",[["b"]]],[" this will help us apply the concept more directly to our model’s performance. There are four terms in the formula for test error:"]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"8ae2f905-a649-44e6-94d2-cb3cfae7007f":{"role":"reader","value":{"id":"8ae2f905-a649-44e6-94d2-cb3cfae7007f","version":2,"type":"text","properties":{"title":[["Test error = irreducible error + bias + variance + validation overfitting",[["i"]]]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"9355b377-2dae-4683-98f6-69a220a9aece":{"role":"reader","value":{"id":"9355b377-2dae-4683-98f6-69a220a9aece","version":2,"type":"numbered_list","properties":{"title":[["Irreducible error",[["b"]]],[" is the baseline error you don’t expect your model to do better. It can be estimated through strong baselines, like human performance."]]},"created_time":1645635848581,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"c779947a-e76c-4e22-82c2-9d032e9c4797":{"role":"reader","value":{"id":"c779947a-e76c-4e22-82c2-9d032e9c4797","version":2,"type":"numbered_list","properties":{"title":[["Avoidable bias",[["b"]]],[", a measure of underfitting, is the difference between our train error and irreducible error."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"701b3e42-ad51-4bb9-bfd1-f51712619882":{"role":"reader","value":{"id":"701b3e42-ad51-4bb9-bfd1-f51712619882","version":2,"type":"numbered_list","properties":{"title":[["Variance",[["b"]]],[", a measure of overfitting, is the difference between validation error and training error."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"cdc4a618-a328-4e6f-b593-fd8b6de86c73":{"role":"reader","value":{"id":"cdc4a618-a328-4e6f-b593-fd8b6de86c73","version":2,"type":"numbered_list","properties":{"title":[["Validation set overfitting",[["b"]]],[" is the difference between test error and validation error."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b841b560-bb41-44ab-b3c9-bca8d3b441d4":{"role":"reader","value":{"id":"b841b560-bb41-44ab-b3c9-bca8d3b441d4","version":2,"type":"text","properties":{"title":[["Consider the chart of learning curves and errors below. Using the test error formula for bias and variance, we can calculate each component of test error and make decisions based on the value. For example, our avoidable bias is rather low (only 2 points), while the variance is much higher (5 points). With this knowledge, we should prioritize methods of preventing overfitting, like regularization."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"65c45cac-8c0d-4c4e-ae06-4b7edf3a9c3d":{"role":"reader","value":{"id":"65c45cac-8c0d-4c4e-ae06-4b7edf3a9c3d","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image12.png"]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"dabfba89-4616-412d-8f8e-7344b23469e1":{"role":"reader","value":{"id":"dabfba89-4616-412d-8f8e-7344b23469e1","version":2,"type":"sub_sub_header","properties":{"title":[["Distribution Shift",[["b"]]]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"13c8d82c-18b7-4eca-98be-c1412057e965":{"role":"reader","value":{"id":"13c8d82c-18b7-4eca-98be-c1412057e965","version":2,"type":"text","properties":{"title":[["Clearly, the application of the bias-variance decomposition to the test error has already helped prioritize our next steps for model development. However, until now, we’ve assumed that the samples (training, validation, testing) all come from the same distribution. What if this isn’t the case? In practical ML situations, this "],["distribution shift",[["b"]]],[" often cars. In building self-driving cars, a frequent occurrence might be training with samples from one distribution (e.g., daytime driving video) but testing or inferring on samples from a totally different distribution (e.g., night time driving)."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ef425645-faa7-4249-aa5b-4cb2ac36f30a":{"role":"reader","value":{"id":"ef425645-faa7-4249-aa5b-4cb2ac36f30a","version":2,"type":"text","properties":{"title":[["A simple way of handling this wrinkle in our assumption is to create two validation sets: one from the training distribution and one from the test distribution. This can be helpful even with a very small testing set. If we apply this, we can actually estimate our distribution shift, which is the difference between testing validation error and testing error. This is really useful for practical applications of ML! With this new term, let’s update our test error formula of bias and variance:"]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ed5d2635-15d1-426c-b50c-f50bc84ecfe8":{"role":"reader","value":{"id":"ed5d2635-15d1-426c-b50c-f50bc84ecfe8","version":2,"type":"text","properties":{"title":[["Test error = irreducible error + bias + variance + distribution shift + validation overfitting",[["i"]]]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"7b62a9d4-3de7-4ba3-94ee-9693447f6de3":{"role":"reader","value":{"id":"7b62a9d4-3de7-4ba3-94ee-9693447f6de3","version":2,"type":"sub_sub_header","properties":{"title":[["6 - Improve Model and Data"]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"d29d70e1-a6cf-4fb7-99d2-ee3823dc28c6":{"role":"reader","value":{"id":"d29d70e1-a6cf-4fb7-99d2-ee3823dc28c6","version":2,"type":"text","properties":{"title":[["Using the updated formula from the last section, we’ll be able to decide on and prioritize the right next steps for each iteration of a model. In particular, we’ll follow a specific process (shown below)."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"fae2fdbc-e79a-421f-bf24-a9395b131b86":{"role":"reader","value":{"id":"fae2fdbc-e79a-421f-bf24-a9395b131b86","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image1.png"]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b47b8e05-a109-475c-99b9-0ed9596ec6d2":{"role":"reader","value":{"id":"b47b8e05-a109-475c-99b9-0ed9596ec6d2","version":2,"type":"sub_sub_header","properties":{"title":[["Step 1: Address Underfitting",[["b"]]]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"95b3bf1d-b3d6-4aec-9555-00674082e53d":{"role":"reader","value":{"id":"95b3bf1d-b3d6-4aec-9555-00674082e53d","version":2,"type":"text","properties":{"title":[["We’ll start by addressing underfitting (i.e., reducing bias). The first thing to try in this case is to make your model bigger (e.g., add layers, more units per layer). Next, consider regularization, which can prevent a tight fit to your data. Other options are error analysis, choosing a different model architecture (e.g., something more state of the art), tuning hyperparameters, or adding features. Some notes:"]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"9cc7d12e-9355-4335-b265-f813fae9c5f7":{"role":"reader","value":{"id":"9cc7d12e-9355-4335-b265-f813fae9c5f7","version":2,"type":"bulleted_list","properties":{"title":[["Choosing different architectures, especially a SOTA one, can be very helpful but is also risky. Bugs are easily introduced in the implementation process."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a570ff5e-d4ce-4ef2-9fa1-6924fdd9cd1f":{"role":"reader","value":{"id":"a570ff5e-d4ce-4ef2-9fa1-6924fdd9cd1f","version":2,"type":"bulleted_list","properties":{"title":[["Adding features is uncommon in the deep learning paradigm (vs. traditional machine learning). We usually want the network to learn features of its own accord. If all else fails, it can be beneficial in a practical setting."]]},"created_time":1645635848582,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b643ac16-0591-45b9-ad37-7b6b60b1a01e":{"role":"reader","value":{"id":"b643ac16-0591-45b9-ad37-7b6b60b1a01e","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image13.png"]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"93ef9497-a2e7-452f-985a-563a021eb47c":{"role":"reader","value":{"id":"93ef9497-a2e7-452f-985a-563a021eb47c","version":2,"type":"sub_sub_header","properties":{"title":[["Step 2: Address Overfitting",[["b"]]]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"50fc1ef5-1242-4f18-ae3c-a97152737845":{"role":"reader","value":{"id":"50fc1ef5-1242-4f18-ae3c-a97152737845","version":2,"type":"text","properties":{"title":[["After addressing underfitting, move on to solving overfitting. Similarly, there’s a recommended series of methods to try in order. Starting with collecting training data (if possible) is the soundest way to address overfitting, though it can be challenging in certain applications. Next, tactical improvements like normalization, data augmentation, and regularization can help. Following these steps, traditional defaults like tuning hyperparameters, choosing a different architecture, or error analysis are useful. Finally, if overfitting is rather intractable, there’s a series of less recommended steps, such as early stopping, removing features, and reducing model size. Early stopping is a personal choice; the fast.ai community is a strong proponent."]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b83b67bc-ed10-4eaa-ac5f-686ac36d49ce":{"role":"reader","value":{"id":"b83b67bc-ed10-4eaa-ac5f-686ac36d49ce","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image15.png"]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6b4b3913-5fd4-48cd-964d-a18720f4d297":{"role":"reader","value":{"id":"6b4b3913-5fd4-48cd-964d-a18720f4d297","version":2,"type":"sub_sub_header","properties":{"title":[["Step 3: Address Distribution Shift",[["b"]]]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"f1f20221-8f79-4737-a527-ebd56b0fa8d3":{"role":"reader","value":{"id":"f1f20221-8f79-4737-a527-ebd56b0fa8d3","version":2,"type":"text","properties":{"title":[["After addressing underfitting and overfitting, If there’s a difference between the error on our training validation set vs. our test validation set, we need to address the error caused by the distribution shift. This is a harder problem to solve, so there’s less in our toolkit to apply."]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"0610ff1c-c119-4295-b36a-7e8117ee38c5":{"role":"reader","value":{"id":"0610ff1c-c119-4295-b36a-7e8117ee38c5","version":2,"type":"text","properties":{"title":[["Start by looking manually at the errors in the test-validation set. Compare the potential logic behind these errors to the performance in the train-validation set, and use the errors to guide further data collection. Essentially, reason about why your model may be suffering from distribution shift error. This is the most principled way to deal with distribution shift, though it’s the most challenging way practically. If collecting more data to address these errors isn’t possible, try synthesizing data. Additionally, you can try "],["domain adaptation",[["b"],["_"],["a","https://ece.engin.umich.edu/wp-content/uploads/2019/09/4142.pdf"]]],["."]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"1d13f597-141e-4426-ad02-aa9b69fd68e6":{"role":"reader","value":{"id":"1d13f597-141e-4426-ad02-aa9b69fd68e6","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image9.png"]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"25677321-009e-4a9a-acb8-e79dc2c5b45d":{"role":"reader","value":{"id":"25677321-009e-4a9a-acb8-e79dc2c5b45d","version":2,"type":"sub_sub_header","properties":{"title":[["ERROR ANALYSIS",[["b"]]]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"03df1634-56a5-4a47-8646-91f3d6032eb0":{"role":"reader","value":{"id":"03df1634-56a5-4a47-8646-91f3d6032eb0","version":2,"type":"text","properties":{"title":[["Manually evaluating errors to understand model performance is generally a high-yield way of figuring out how to improve the model. Systematically performing this "],["error analysis",[["b"]]],[" process and decomposing the error from different error types can help prioritize model improvements. For example, in a self-driving car use case with error types like hard-to-see pedestrians, reflections, and nighttime scenes, decomposing the error contribution of each and where it occurs (train-val vs. test-val) can give rise to a clear set of prioritized action items. See the table for an example of how this error analysis can be effectively structured."]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"63082208-00d3-41dd-b0ba-adfd3794c9d6":{"role":"reader","value":{"id":"63082208-00d3-41dd-b0ba-adfd3794c9d6","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image5.png"]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e8c55e41-b1c2-4a2d-96ed-4ead437558cf":{"role":"reader","value":{"id":"e8c55e41-b1c2-4a2d-96ed-4ead437558cf","version":2,"type":"sub_sub_header","properties":{"title":[["DOMAIN ADAPTATION",[["b"]]]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a6b4ab4d-86bc-49a3-83d3-2bdd0b348cad":{"role":"reader","value":{"id":"a6b4ab4d-86bc-49a3-83d3-2bdd0b348cad","version":2,"type":"text","properties":{"title":[["Domain adaptation is a class of techniques that train on a “source” distribution and generalize to another “target” using only unlabeled data or limited labeled data. You should use domain adaptation when access to labeled data from the test distribution is limited, but access to relatively similar data is plentiful."]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"80c75dff-bbbc-4a2f-8bba-b5118c2f91ad":{"role":"reader","value":{"id":"80c75dff-bbbc-4a2f-8bba-b5118c2f91ad","version":2,"type":"text","properties":{"title":[["There are a few different types of domain adaptation:"]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"481b6135-9313-4a56-90e0-092d61f794cb":{"role":"reader","value":{"id":"481b6135-9313-4a56-90e0-092d61f794cb","version":2,"type":"numbered_list","properties":{"title":[["Supervised domain adaptation",[["b"]]],[": In this case, we have limited data from the target domain to adapt to. Some example applications of the concept include fine-tuning a pre-trained model or adding target data to a training set."]]},"created_time":1645635848583,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"aa718d5a-ab1b-4d53-80aa-8874f10bf0f5":{"role":"reader","value":{"id":"aa718d5a-ab1b-4d53-80aa-8874f10bf0f5","version":2,"type":"numbered_list","properties":{"title":[["Unsupervised domain adaptation",[["b"]]],[": In this case, we have lots of unlabeled data from the target domain. Some techniques you might see are CORAL, domain confusion, and CycleGAN."]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"f418364e-f36e-46d5-9bb0-20fd02c886bf":{"role":"reader","value":{"id":"f418364e-f36e-46d5-9bb0-20fd02c886bf","version":2,"type":"text","properties":{"title":[["Practically speaking, supervised domain adaptation can work really well! Unsupervised domain adaptation has a little bit further to go."]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"848bb57e-f69c-4716-86cd-79d83b465110":{"role":"reader","value":{"id":"848bb57e-f69c-4716-86cd-79d83b465110","version":2,"type":"sub_sub_header","properties":{"title":[["Step 4: Rebalance datasets",[["b"]]]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b8cc1833-7e93-44a1-89f1-6e56ffb21657":{"role":"reader","value":{"id":"b8cc1833-7e93-44a1-89f1-6e56ffb21657","version":2,"type":"text","properties":{"title":[["If the test-validation set performance starts to look considerably better than the test performance, you may have overfit the validation set. This commonly occurs with small validation sets or lots of hyperparameter training. If this occurs, resample the validation set from the test distribution and get a fresh estimate of the performance."]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"0e5f8906-0d7b-4084-b2b3-fbc908e98b59":{"role":"reader","value":{"id":"0e5f8906-0d7b-4084-b2b3-fbc908e98b59","version":2,"type":"sub_sub_header","properties":{"title":[["7 - Tune Hyperparameters"]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ac79660c-5c72-4ebf-a167-71a3891c3f2b":{"role":"reader","value":{"id":"ac79660c-5c72-4ebf-a167-71a3891c3f2b","version":2,"type":"text","properties":{"title":[["One of the core challenges in hyperparameter optimization is very basic: "],["which hyperparameters should you tune?",[["b"]]],[" As we consider this fundamental question, let’s keep the following in mind:"]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"c721d6c5-86e7-4556-9bc7-de85e0bcc330":{"role":"reader","value":{"id":"c721d6c5-86e7-4556-9bc7-de85e0bcc330","version":2,"type":"bulleted_list","properties":{"title":[["Models are more sensitive to some hyperparameters than others. This means we should focus our efforts on the more impactful hyperparameters."]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"2c76c89e-cb56-438d-9859-6127869bd459":{"role":"reader","value":{"id":"2c76c89e-cb56-438d-9859-6127869bd459","version":2,"type":"bulleted_list","properties":{"title":[["However, which hyperparameters are most important depends heavily on our choice of model."]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"c6586382-1b05-46e3-9b3a-0d1fb17b4b5e":{"role":"reader","value":{"id":"c6586382-1b05-46e3-9b3a-0d1fb17b4b5e","version":2,"type":"bulleted_list","properties":{"title":[["Certain rules of thumbs can help guide our initial thinking."]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"b23c9a46-a040-4140-8acb-2dc3add0b0dc":{"role":"reader","value":{"id":"b23c9a46-a040-4140-8acb-2dc3add0b0dc","version":2,"type":"bulleted_list","properties":{"title":[["Sensitivity is always relative to default values; if you use good defaults, you might start in a good place!"]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"9cd74b51-a6f3-44ee-8cf1-b8758a9146ce":{"role":"reader","value":{"id":"9cd74b51-a6f3-44ee-8cf1-b8758a9146ce","version":2,"type":"text","properties":{"title":[["See the following table for a ranked list of hyperparameters and their impact on the model:"]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a2c45c2b-c999-4bd1-93ba-1a7cbfee5b36":{"role":"reader","value":{"id":"a2c45c2b-c999-4bd1-93ba-1a7cbfee5b36","version":2,"type":"image","properties":{"source":[["https://fullstackdeeplearning.com/spring2021/lecture-7-notes-media/image2.png"]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"bc5e35e3-be9e-425f-b1a4-742286d7924a":{"role":"reader","value":{"id":"bc5e35e3-be9e-425f-b1a4-742286d7924a","version":2,"type":"sub_sub_header","properties":{"title":[["Techniques for Tuning Hyperparameter Optimization",[["b"]]]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"6d52c5d6-2aaf-4d89-8ad0-ceba80efd903":{"role":"reader","value":{"id":"6d52c5d6-2aaf-4d89-8ad0-ceba80efd903","version":2,"type":"text","properties":{"title":[["Now that we know which hyperparameters make the most sense to tune (using rules of thumb), let’s consider the various methods of actually tuning them:"]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ba78d23c-4bf6-458a-9379-86d9af3c268a":{"role":"reader","value":{"id":"ba78d23c-4bf6-458a-9379-86d9af3c268a","version":2,"type":"numbered_list","properties":{"title":[["Manual Hyperparameter Optimization",[["b"]]],[". Colloquially referred to as Graduate Student Descent, this method works by taking a manual, detailed look at your algorithm, building intuition, and considering which hyperparameters would make the most difference. After figuring out these parameters, you train, evaluate, and guess a better hyperparameter value using your intuition for the algorithm and intelligence. While it may seem archaic, this method combines well with other methods (e.g., setting a range of values for hyperparameters) and has the main benefit of reducing computation time and cost if used skillfully. It can be time-consuming and challenging, but it can be a good starting point."]]},"created_time":1645635848584,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"220ef235-283b-4e8b-ad6c-a9467c7c91cd":{"role":"reader","value":{"id":"220ef235-283b-4e8b-ad6c-a9467c7c91cd","version":2,"type":"numbered_list","properties":{"title":[["Grid Search",[["b"]]],[". Imagine each of your parameters plotted against each other on a grid, from which you uniformly sample values to test. For each point, you run a training run and evaluate performance. The advantages are that it’s very simple and can often produce good results. However, it’s quite inefficient, as you must run every combination of hyperparameters. It also often requires prior knowledge about the hyperparameters since we must manually set the range of values."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"df9e48a9-7dee-4012-96e0-2534c8518f39":{"role":"reader","value":{"id":"df9e48a9-7dee-4012-96e0-2534c8518f39","version":2,"type":"numbered_list","properties":{"title":[["Random Search",[["b"]]],[": This method is recommended over grid search. Rather than sampling from the grid of values for the hyperparameter evenly, we’ll choose n points sampled randomly across the grid. Empirically, this method produces better results than grid search. However, the results can be somewhat uninterpretable, with unexpected values in certain hyperparameters returned."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"2e9fb20f-03d5-4427-a28c-8f02427ca02e":{"role":"reader","value":{"id":"2e9fb20f-03d5-4427-a28c-8f02427ca02e","version":2,"type":"numbered_list","properties":{"title":[["Coarse-to-fine Search",[["b"]]],[": Rather than running entirely random runs, we can gradually narrow in on the best hyperparameters through this method. Initially, start by defining a very large range to run a randomized search on. Within the pool of results, you can find N best results and hone in on the hyperparameter values used to generate those samples. As you iteratively perform this method, you can get excellent performance. This doesn’t remove the manual component, as you have to select which range to continuously narrow your search to, but it’s perhaps the most popular method available."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"86558bbf-283d-4126-a2fb-d1884a8a938e":{"role":"reader","value":{"id":"86558bbf-283d-4126-a2fb-d1884a8a938e","version":2,"type":"numbered_list","properties":{"title":[["Bayesian Hyperparameter Optimization",[["b"]]],[": This is a reasonably sophisticated method, which you can read more about "],["here",[["b"],["_"],["a","http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec21.pdf"]]],[" and "],["here",[["b"],["_"],["a","https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"]]],[". At a high level, start with a prior estimate of parameter distributions. Subsequently, maintain a probabilistic model of the relationship between hyperparameter values and model performance. As you maintain this model, you toggle between training with hyperparameter values that maximize the expected improvement (per the model) and use training results to update the initial probabilistic model and its expectations. This is a great, hands-off, efficient method to choose hyperparameters. However, these techniques can be quite challenging to implement from scratch. As libraries and infrastructure mature, the integration of these methods into training will become easier."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"a2c44c7f-975a-439c-a47b-841e3921d1a7":{"role":"reader","value":{"id":"a2c44c7f-975a-439c-a47b-841e3921d1a7","version":2,"type":"text","properties":{"title":[["In summary, you should probably start with coarse-to-fine random searches and move to Bayesian methods as your codebase matures and you’re more certain of your model."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"2956286a-a232-4820-99c8-c9fd4c307182":{"role":"reader","value":{"id":"2956286a-a232-4820-99c8-c9fd4c307182","version":2,"type":"sub_sub_header","properties":{"title":[["8 - Conclusion"]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"639d9f20-0fab-4e75-acfe-af995d9b9434":{"role":"reader","value":{"id":"639d9f20-0fab-4e75-acfe-af995d9b9434","version":2,"type":"text","properties":{"title":[["To wrap up this lecture, deep learning troubleshooting and debugging is really hard. It’s difficult to tell if you have a bug because there are many possible sources for the same degradation in performance. Furthermore, the results can be sensitive to small changes in hyper-parameters and dataset makeup."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e23a34ec-d505-4cdb-86fe-1e4b82d32072":{"role":"reader","value":{"id":"e23a34ec-d505-4cdb-86fe-1e4b82d32072","version":2,"type":"text","properties":{"title":[["To train bug-free deep learning models, we need to treat building them as an iterative process. If you skipped to the end, the following steps can make this process easier and catch errors as early as possible:"]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"45c565fa-95d1-4dba-abb5-9a80d1d2a493":{"role":"reader","value":{"id":"45c565fa-95d1-4dba-abb5-9a80d1d2a493","version":2,"type":"bulleted_list","properties":{"title":[["Start Simple",[["b"]]],[": Choose the simplest model and data possible."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ae01af56-fa53-4ce5-965c-bc1210a645e9":{"role":"reader","value":{"id":"ae01af56-fa53-4ce5-965c-bc1210a645e9","version":2,"type":"bulleted_list","properties":{"title":[["Implement and Debug",[["b"]]],[": Once the model runs, overfit a single batch and reproduce a known result."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"84039c01-ee09-4c49-a9dc-5f425e9b97fd":{"role":"reader","value":{"id":"84039c01-ee09-4c49-a9dc-5f425e9b97fd","version":2,"type":"bulleted_list","properties":{"title":[["Evaluate",[["b"]]],[": Apply the bias-variance decomposition to decide what to do next."]]},"created_time":1645635848585,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"91635917-fdca-406d-bf3b-382c1765e3f8":{"role":"reader","value":{"id":"91635917-fdca-406d-bf3b-382c1765e3f8","version":2,"type":"bulleted_list","properties":{"title":[["Tune Hyper-parameters",[["b"]]],[": Use coarse-to-fine random searches to tune the model’s hyper-parameters."]]},"created_time":1645635848586,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ec70b5e2-baa8-4432-9468-a92a469a6843":{"role":"reader","value":{"id":"ec70b5e2-baa8-4432-9468-a92a469a6843","version":2,"type":"bulleted_list","properties":{"title":[["Improve Model and Data",[["b"]]],[": Make your model bigger if your model under-fits and add more data and/or regularization if your model over-fits."]]},"created_time":1645635848586,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"ab654ab4-2f3a-4d3a-923e-68c060cf31b8":{"role":"reader","value":{"id":"ab654ab4-2f3a-4d3a-923e-68c060cf31b8","version":2,"type":"text","properties":{"title":[["Here are additional resources that you can go to learn more:"]]},"created_time":1645635848586,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"79247fa9-4d53-4a8c-ab28-40ac3d768e39":{"role":"reader","value":{"id":"79247fa9-4d53-4a8c-ab28-40ac3d768e39","version":2,"type":"bulleted_list","properties":{"title":[["Andrew Ng’s “"],["Machine Learning Yearning",[["b"],["_"],["a","https://www.deeplearning.ai/machine-learning-yearning/"]]],["” book."]]},"created_time":1645635848586,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"e9cbabbb-d571-42eb-a62d-64c952348cde":{"role":"reader","value":{"id":"e9cbabbb-d571-42eb-a62d-64c952348cde","version":2,"type":"bulleted_list","properties":{"title":[["This "],["Twitter thread",[["b"],["_"],["a","https://twitter.com/karpathy/status/1013244313327681536"]]],[" from Andrej Karpathy."]]},"created_time":1645635848586,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}},"eed49f33-5d7b-4f6f-bfcd-6456c8c73133":{"role":"reader","value":{"id":"eed49f33-5d7b-4f6f-bfcd-6456c8c73133","version":2,"type":"bulleted_list","properties":{"title":[["BYU’s “"],["Practical Advice for Building Deep Neural Networks",[["b"],["_"],["a","https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neural-networks/"]]],["” blog post."]]},"created_time":1645635848586,"last_edited_time":1645635840000,"parent_id":"94cea945-881b-4d6b-be5c-505834b715db","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","last_edited_by_table":"notion_user","last_edited_by_id":"9e9c4442-4350-473a-b900-c954b0bd7a95","space_id":"bb9288f4-efb5-417f-bf44-1a79fa04feb1"}}},"space":{},"discussion":{},"comment":{},"collection":{},"collection_view":{},"notion_user":{},"collection_query":{},"signed_urls":{},"preview_images":{}},"pageId":"94cea945-881b-4d6b-be5c-505834b715db"},"__N_SSG":true},"page":"/[pageId]","query":{"pageId":"troubleshooting-deep-neural-networks"},"buildId":"9poW2wwFjweYMtUtYyNUe","assetPrefix":"/blog","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>